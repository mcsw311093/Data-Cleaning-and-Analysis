{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library \n",
    "\n",
    "import re\n",
    "import requests\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd \n",
    "import csv\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_columns', 100)\n",
    "from IPython.core import display as ICD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Text Normalization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_windows_1252_characters(restore_string):\n",
    "    \"\"\"\n",
    "    Replace C1 control characters in the Unicode string s by the\n",
    "    characters at the corresponding code points in Windows-1252,\n",
    "    where possible.\n",
    "    \"\"\"\n",
    "\n",
    "def to_windows_1252(match):\n",
    "    try:\n",
    "        return bytes([ord(match.group(0))]).decode('windows-1252')\n",
    "    except UnicodeDecodeError:\n",
    "        # No character at the corresponding code point: remove it.\n",
    "        return ''\n",
    "\n",
    "    return re.sub(r'[\\u0080-\\u0099]', to_windows_1252, restore_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab the Document Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_doc_content( brand, CIK ):\n",
    "    \n",
    "    company = {}\n",
    "    \n",
    "    company['auto'] = {}\n",
    "    auto = {brand : CIK\n",
    "           }\n",
    "    company['auto'] = auto\n",
    "\n",
    "    value = list(auto.copy().values())\n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDC = grab_doc_content('Apple', '0000320193')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_filings_dict = {}\n",
    "    \n",
    "file_code = {}\n",
    "    \n",
    "file_text = {}\n",
    "\n",
    "Accession_Number_URL = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL Directory For CIK    \n",
    "dir_url = r'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type=10-&dateb=&owner=include&count=100'\n",
    "dir_url_list = [dir_url.format(x) for x in GDC]\n",
    "\n",
    "#print('Directory URL: {}'.format(dir_url_list))\n",
    "doc_url_list = [] \n",
    "\n",
    "# FOR-loop yielding Accession Numbers from CIK/URL Directory.\n",
    "for CIK_num in GDC:\n",
    "\n",
    "    doc_url = r'https://www.sec.gov/Archives/edgar/data/{CIKx}/{xx}/{yy}.txt'\n",
    "    doc_url_new = doc_url.format(CIKx = CIK_num, xx='{xx}', yy ='{yy}')\n",
    "    doc_url_list.append(doc_url_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_maker(dir_url):\n",
    "    dir_url_list = [dir_url.format(x) for x in GDC]\n",
    "\n",
    "    #print('Directory URL: {}'.format(dir_url_list))\n",
    "    doc_url_list = [] \n",
    "\n",
    "    # FOR-loop yielding Accession Numbers from CIK/URL Directory.\n",
    "    for CIK_num in GDC:\n",
    "\n",
    "        doc_url = r'https://www.sec.gov/Archives/edgar/data/{CIKx}/{xx}/{yy}.txt'\n",
    "        doc_url_new = doc_url.format(CIKx = CIK_num, xx='{xx}', yy ='{yy}')\n",
    "        \n",
    "        doc_url_list.append(doc_url_new)\n",
    "        \n",
    "        url_lists = zip( dir_url_list , doc_url_list )\n",
    "        \n",
    "    return url_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=0000320193&type=10-&dateb=&owner=include&count=100\n",
      "2 https://www.sec.gov/Archives/edgar/data/0000320193/{xx}/{yy}.txt\n"
     ]
    }
   ],
   "source": [
    "url = r'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type=10-&dateb=&owner=include&count=100'\n",
    "for dir_url, doc_url in url_maker(url): \n",
    "    print(1, dir_url)\n",
    "    print(2, doc_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accession_Number_URL = {}\n",
    "url = r'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type=10-&dateb=&owner=include&count=100'\n",
    "\n",
    "for dir_url, doc_url in url_maker(url):\n",
    "    \n",
    "    response = requests.get(dir_url)\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "    text = soup.get_text(strip=True)\n",
    "\n",
    "    cleaned_text = re.findall('Acc-no: \\d+-\\d+-\\d+' , text)\n",
    "\n",
    "    accession_number = [n.replace('Acc-no: ', '') for n in cleaned_text]\n",
    "    accessionnumber = [num.replace('-', '') for num in accession_number]\n",
    "\n",
    "    accession_numbers = zip(accessionnumber, accession_number)\n",
    "    \n",
    "    cikk = [ cikk_.replace('CIK=', '') for cikk_ in re.findall('CIK=\\d+', dir_url) ][0]\n",
    "    CIKK = {cikk : accessionnumber}\n",
    "    \n",
    "    for (a,b) in accession_numbers: \n",
    "        master_filings_dict[b] = {}\n",
    "        master_filings_dict[b]['sec_header_content'] = {}\n",
    "        master_filings_dict[b]['filing_documents'] = None\n",
    "\n",
    "        doc_url_single = doc_url.format(xx = a, yy = b)\n",
    "\n",
    "        file_url_list = []\n",
    "\n",
    "        \n",
    "\n",
    "        file_url_list.append( doc_url_single )\n",
    "        \n",
    "        Accession_Number_URL.update({ b : file_url_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000320193-20-000052', '0000320193-20-000010', '0000320193-19-000119', '0000320193-19-000076', '0000320193-19-000066', '0000320193-19-000010', '0000320193-18-000145', '0000320193-18-000100', '0000320193-18-000070', '0000320193-18-000007', '0000320193-17-000070', '0000320193-17-000009', '0001628280-17-004790', '0001628280-17-000717', '0001628280-16-020309', '0001628280-16-017809', '0001193125-16-559625', '0001193125-16-439878', '0001193125-15-356351', '0001193125-15-259935', '0001193125-15-153166', '0001193125-15-023697', '0001193125-14-383437', '0001193125-14-277160', '0001193125-14-157311', '0001193125-14-024487'] \n",
      "\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "A_N = []\n",
    "for AN, url in Accession_Number_URL.items():\n",
    "    \n",
    "    if AN == '0001193125-13-416534':\n",
    "        break\n",
    "    else:\n",
    "        A_N.append(AN)\n",
    "print(A_N, '\\n')\n",
    "print(len(A_N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save each Filing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "The document 10-Q was parsed.\n",
      "There was 38 page(s) found.\n",
      "There was 38 thematic breaks(s) found.\n",
      "--------------------------------------------------------------------------------\n",
      "All the documents for filing 0000320193-20-000052 were parsed and stored.\n"
     ]
    }
   ],
   "source": [
    "QorK = {'10-Q' : [],\n",
    "        '10-K' : []\n",
    "       }\n",
    "\n",
    "for acc_num, url in Accession_Number_URL.items():\n",
    "    \n",
    "    master_document_dict = {}\n",
    "    \n",
    "    # create a stop point\n",
    "    if acc_num == '0000320193-20-000010':\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # grab the response\n",
    "        response = requests.get(url[0])\n",
    "\n",
    "    # Soupify\n",
    "        # pass it through the parser, in this case let's just use lxml because the tags seem to follow xml.\n",
    "        soup = BeautifulSoup(response.content, 'lxml')\n",
    "        filing_document = soup.find('document')\n",
    "        \n",
    "    # Parsing\n",
    "        # Document type ->> document_id\n",
    "        document_id = filing_document.type.find(text=True, recursive=False).strip()\n",
    "        # Document sequence ->> document_sequence\n",
    "        document_sequence = filing_document.sequence.find(text=True, recursive=False).strip()\n",
    "        # Document filename ->> document_filename\n",
    "        document_filename = filing_document.filename.find(text=True, recursive=False).strip()\n",
    "        # Document description ->> document_description\n",
    "        document_description = filing_document.description.find(text=True, recursive=False).strip()\n",
    "        \n",
    "    # Storage    \n",
    "        # initalize our document dictionary\n",
    "        master_document_dict[document_id] = {}\n",
    "\n",
    "        # add the different parts, we parsed up above.\n",
    "        master_document_dict[document_id]['document_sequence'] = document_sequence\n",
    "        master_document_dict[document_id]['document_filename'] = document_filename\n",
    "        master_document_dict[document_id]['document_description'] = document_description\n",
    "        \n",
    "# Scraping\n",
    "        # grab the text portion of the document, this will be used to split the document into pages.\n",
    "        filing_doc_text = filing_document.find('text').extract()\n",
    "\n",
    "        # find all the thematic breaks, these help define page numbers and page breaks.\n",
    "        all_thematic_breaks = filing_doc_text.find_all('hr')\n",
    "\n",
    "        # Locate and store page number via list comprehension.\n",
    "        all_page_numbers = [thematic_break.previous_sibling.get_text(strip=True) for thematic_break in all_thematic_breaks if len(str(thematic_break))>6]\n",
    "\n",
    "        # convert all thematic breaks to a string so it can be used for parsing\n",
    "        all_thematic_breaks = [str(thematic_break) for thematic_break in all_thematic_breaks]\n",
    "\n",
    "        # prep the document text for splitting, this means converting it to a string.\n",
    "        filing_doc_string = str(filing_doc_text)\n",
    "    \n",
    "        # handle the case where there are thematic breaks.\n",
    "        if len(all_thematic_breaks) > 0: \n",
    "\n",
    "            # define the regex delimiter pattern, this would just be all of our thematic breaks.\n",
    "            regex_delimiter_pattern = '|'.join(map(re.escape, all_thematic_breaks))\n",
    "\n",
    "            # split the document along each thematic break.\n",
    "            split_filing_string = re.split(regex_delimiter_pattern, filing_doc_string)\n",
    "\n",
    "            # store the document itself\n",
    "            master_document_dict[document_id]['pages_code'] = split_filing_string\n",
    "\n",
    "        # handle the case where there are no thematic breaks.\n",
    "        elif len(all_thematic_breaks) == 0:\n",
    "\n",
    "            # handles so it will display correctly.\n",
    "            split_filing_string = all_thematic_breaks\n",
    "\n",
    "            # store the document as is, since there are no thematic breaks. In other words, no splitting.\n",
    "            master_document_dict[document_id]['pages_code'] = [filing_doc_string]\n",
    "            \n",
    "        # display some information to the user.\n",
    "        print('-'*80)\n",
    "        print('The document {} was parsed.'.format(document_id))\n",
    "        print('There was {} page(s) found.'.format(len(all_page_numbers)))\n",
    "        print('There was {} thematic breaks(s) found.'.format(len(all_thematic_breaks)))\n",
    "\n",
    "        # store the documents in the master_filing_dictionary.\n",
    "        master_filings_dict[acc_num]['filing_documents'] = master_document_dict\n",
    "        \n",
    "        # if document is 10-Q\n",
    "        if document_id == '10-Q':\n",
    "            QorK['10-Q'].append(acc_num) # add acc_num to QorK in 10-Q as key\n",
    "        \n",
    "        # if document is 10-K\n",
    "        if document_id == '10-K':\n",
    "            QorK['10-K'].append(acc_num) # add acc_num to QorK in 10-K as key\n",
    "        \n",
    "        del master_document_dict\n",
    "        \n",
    "        print('-'*80)\n",
    "        print('All the documents for filing {} were parsed and stored.'.format(acc_num))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_test = master_filings_dict['0000320193-20-000052']['filing_documents']['10-Q']['pages_code']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Check Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variations of HTML anchors.\n",
    "CBS_A = 'CONDENSED CONSOLIDATED BALANCE SHEETS'\n",
    "CBS_B = 'CONSOLIDATED BALANCE SHEETS'\n",
    "# SoO_A = '<a name=\"Statements_of_Operations\"' \n",
    "# SoO_B = 'id=\"CONSOLIDATED_STATEMENTS_OPERATIONS\"'\n",
    "# SoO3 = 'name=\"CONSOLIDATED_STATEMENTS_OPERATIONS\"'\n",
    "# CSoO10K = 'name=\"Consolidated_Statements_of_Operations\"'\n",
    "# CSoO10Knew = 'id=\"Consolidated_Statements_of_Operations\"'\n",
    "\n",
    "# CF_A = '<a name=\"Statements_of_Cash'\n",
    "# CF_B = 'id=\"CONSOLIDATED_STATEMENTS_CASH_FLOWS\"'\n",
    "# CF3 = 'name=\"CONSOLIDATED_STATEMENTS_CASH_FLOWS\"'\n",
    "# CCF10K = 'name=\"Consolidated_Statements_of_Cash_Flows\"'\n",
    "# CCF10Knew = 'id=\"Consolidated_Statements_of_Cash_Flows\"'\n",
    "\n",
    "def anchor_check(page_code):\n",
    "    \n",
    "    # if the page has one of these anchors\n",
    "    if (CBS_A in page_code) or (CBS_B in page_code):\n",
    "        return True\n",
    "\n",
    "    #elif (SoO_A in page_code) or (SoO_B in page_code) or (SoO3 in page_code) or (CSoO10K in page_code) or (CSoO10Knew in page_code) :\n",
    "        #return True\n",
    "\n",
    "    #elif (CF_A in page_code) or (CF_B in page_code) or (CF3 in page_code) or (CCF10K in page_code) or (CCF10Knew in page_code):\n",
    "        #return True\n",
    "\n",
    "\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Columns Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {'December' : 'Q4',\n",
    "              'November' : 'Q4',\n",
    "             'October' : 'Q4',\n",
    "             'September' : 'Q3',\n",
    "             'August': 'Q3',\n",
    "             'July' : 'Q3',\n",
    "             'June' : 'Q2',\n",
    "             'May' : 'Q2',\n",
    "             'April' : 'Q2',\n",
    "             'March' : 'Q1',\n",
    "             'Feburary' : 'Q1',\n",
    "             'January' : 'Q1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortening Column name.\n",
    "def clean_col_name( element ):\n",
    "    \n",
    "    if re.findall('Common stock.*', element):\n",
    "        \n",
    "        element = element.replace(element, 'Common Stock') \n",
    "\n",
    "        return element\n",
    "        \n",
    "    elif re.findall('Preferred stock.*', element):\n",
    "        \n",
    "        element = element.replace(element, 'Preferred Stock') \n",
    "        \n",
    "        return element\n",
    "    \n",
    "    elif re.findall(\"Total liabilities and stockholders' equity.*\", element):\n",
    "        \n",
    "        element = element.replace(element, 'Total liabilities and equity' ) \n",
    "        \n",
    "        return element\n",
    "\n",
    "    elif re.findall('Accounts receivable.*', element):\n",
    "        \n",
    "        element = element.replace(element, 'Accounts receivable' ) \n",
    "        \n",
    "        return element\n",
    "\n",
    "    elif re.findall('Accrued liabilities.*', element):\n",
    "        \n",
    "        element = element.replace(element, 'Accrued Liabilities' ) \n",
    "        \n",
    "        return element\n",
    "\n",
    "    elif re.findall('Deferred revenue.*', element):\n",
    "        \n",
    "        element = element.replace(element, 'Deferred Revenue' ) \n",
    "        \n",
    "        return element\n",
    "\n",
    "    elif re.findall('Redeemable noncontrolling interests in subsidiaries.*', element):\n",
    "        \n",
    "        element = element.replace(element, 'Noncontrolling interests in subsidiaries' ) \n",
    "        \n",
    "        return element\n",
    "    \n",
    "    elif re.findall('Convertible senior notes.*', element, flags=re.I):\n",
    "        #print('before: ', element)\n",
    "        element = element.replace(element, 'Convertible Senior Notes' )\n",
    "        #print('after: ', element)\n",
    "        return element\n",
    "    \n",
    "    else:\n",
    "        return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throw column list-like object into cleaning function. \n",
    "def cleaning_column(column, m):\n",
    "     \n",
    "    column_list = []\n",
    "\n",
    "    for element_post, element in enumerate(column):\n",
    "        \n",
    "        # Handling the first \"row\" in the table i.e. column name.\n",
    "        if element_post == 0:\n",
    "\n",
    "            element = unicodedata.normalize('NFKD', element)\n",
    "            \n",
    "            element = element.replace( '\\n', '')\n",
    "            \n",
    "            clean_ele = clean_col_name( element )\n",
    "            \n",
    "            column_list.append(clean_ele)\n",
    "            \n",
    "        # Use a dictionary to convert the Months into numbers.\n",
    "        #elif element_post == :\n",
    "            #month = re.sub('({})'.format('|'.join(map(re.escape, month_dict.keys()))), lambda m: month_dict[m.group()], dat)\n",
    "            #column_list.extend(month)\n",
    "        #elif element == '(' or ')': \n",
    "            #pint(element)\n",
    "            #continue\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            element = element.replace( '\\n$' and '\\n\\xa0' and '\\n', '0')\n",
    "            \n",
    "            element = element.replace( ',', '' )\n",
    "\n",
    "            pattern = re.compile(r'[\\d]+,[\\d]+|[\\d]+')\n",
    "\n",
    "            res = pattern.findall(element)\n",
    "\n",
    "            res = [int(ele) * m for ele in res]\n",
    "\n",
    "            column_list.extend(res)\n",
    "\n",
    "    return column_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Tables Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quarter( column ):\n",
    "    \n",
    "    D = []\n",
    "    Q = []\n",
    "    Y = []\n",
    "    \n",
    "    for ele_num, ele in enumerate(column):\n",
    "        \n",
    "\n",
    "        date_data = re.sub('({})'.format('|'.join(map(re.escape, month_dict.keys()))), lambda m: month_dict[m.group()], ele)\n",
    "\n",
    "        pattern = re.compile(r'\\w+')\n",
    "\n",
    "        res = pattern.findall(date_data)\n",
    "        \n",
    "        D.append(res)\n",
    "        \n",
    "    D = [i for i in D if i]\n",
    "    print(D)\n",
    "    Q.append(D[0][0])\n",
    "    Q.insert(0, 'Quarter')\n",
    "    \n",
    "    Y.append(D[0][2])\n",
    "    Y.insert(0, 'Year')\n",
    "    \n",
    "    return Q, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_extractor( page, multiplier, k ):\n",
    "    \n",
    "    # Convert string to BS object\n",
    "    soup = BeautifulSoup(page, 'html5')\n",
    "\n",
    "    # then get all the rows in the table.\n",
    "    table_rows = soup.find_all('tr')\n",
    "    \n",
    "    if len( [tr.text for tr in table_rows[0].find_all('td')] ) < 3:\n",
    "        del table_rows[0]\n",
    "    \n",
    "    single_table = []\n",
    "    \n",
    "    # Loop through each column, adding in three structures to single_table.\n",
    "    for tr_post, tr in enumerate(table_rows):\n",
    "        \n",
    "        td = tr.find_all('td')\n",
    "\n",
    "        column = [tr.text for tr in td]\n",
    "        print( tr_post, len(column), column)\n",
    "        # 10-Q \n",
    "        if k == '10-Q':\n",
    "            \n",
    "            if tr_post == 1:\n",
    "\n",
    "                # Quarter Column\n",
    "                col_Q, col_year = Quarter( column )\n",
    "                single_table.append( col_Q )\n",
    "                # Year Column\n",
    "                single_table.append( col_year )\n",
    "\n",
    "            elif tr_post > 1: \n",
    "\n",
    "                # Features Columns\n",
    "                cleaned_data = cleaning_column( column , multiplier )\n",
    "                if len(cleaned_data) > 10:\n",
    "                    del cleaned_data[3]\n",
    "                    \n",
    "                single_table.append( cleaned_data )\n",
    "                \n",
    "        # 10-K\n",
    "        elif k == '10-K':\n",
    "                \n",
    "            if tr_post == 2:\n",
    "                \n",
    "                # Quarter Column\n",
    "                col_date, col_year = Quarter( column )\n",
    "                single_table.append( col_date )\n",
    "                # Year Column\n",
    "                single_table.append( col_year )\n",
    "\n",
    "            elif tr_post > 5: \n",
    "                \n",
    "                cleaned_data = cleaning_column( column , 10**6 )\n",
    "                if len(cleaned_data) > 10:\n",
    "                    del cleaned_data[3]\n",
    "                \n",
    "                single_table.append( cleaned_data )\n",
    "            \n",
    "    return single_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_clean( single_table ):\n",
    "    #print(single_table)\n",
    "    table_df = pd.DataFrame(single_table)\n",
    "\n",
    "    table_df = table_df.transpose()  \n",
    "\n",
    "    #table_df.drop(table_df.index[1:3], 0, inplace=True)\n",
    "\n",
    "    #table_df.drop(table_df.index[2:], 0, inplace=True)\n",
    "\n",
    "    table_df.columns = table_df.iloc[0]\n",
    "\n",
    "    table_df = table_df.drop(table_df.index[0])\n",
    "    \n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(page_code, k):\n",
    "    \n",
    "    doc_tables=[]\n",
    "\n",
    "    for page_post, page in enumerate(page_code):\n",
    "        \n",
    "        if anchor_check(page) and ('in millions' in page):\n",
    "            \n",
    "            single_table = table_extractor( page, 10**6, k )\n",
    "            \n",
    "            table_df = df_clean(single_table)\n",
    "                        \n",
    "            doc_tables.append(table_df)\n",
    "        \n",
    "        elif anchor_check(page) and ('in thousands' in page):\n",
    "            \n",
    "            single_table = table_extractor( page, 10**3, k )\n",
    "            \n",
    "            table_df = df_clean(single_table)\n",
    "            \n",
    "            doc_tables.append(table_df)\n",
    "            \n",
    "                \n",
    "    return doc_tables\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10-Q': ['0000320193-20-000052'], '10-K': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QorK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8 ['', '', '', '', '', '', '', '']\n",
      "1 4 ['\\xa0', 'March\\xa028, 2020', '\\xa0', 'September\\xa028, 2019']\n",
      "[['Q1', '28', '2020'], ['Q3', '28', '2019']]\n",
      "2 1 ['ASSETS:']\n",
      "3 4 ['Current assets:', '\\xa0', '\\xa0', '\\xa0']\n",
      "4 8 ['Cash and cash equivalents', '$', '40,174', '', '\\xa0', '$', '48,844', '']\n",
      "5 6 ['Marketable securities', '53,877', '', '\\xa0', '51,713', '']\n",
      "6 6 ['Accounts receivable, net', '15,722', '', '\\xa0', '22,926', '']\n",
      "7 6 ['Inventories', '3,334', '', '\\xa0', '4,106', '']\n",
      "8 6 ['Vendor non-trade receivables', '14,955', '', '\\xa0', '22,878', '']\n",
      "9 6 ['Other current assets', '15,691', '', '\\xa0', '12,352', '']\n",
      "10 6 ['Total current assets', '143,753', '', '\\xa0', '162,819', '']\n",
      "11 4 ['\\xa0', '\\xa0', '\\xa0', '\\xa0']\n",
      "12 4 ['Non-current assets:', '\\xa0', '\\xa0', '\\xa0']\n",
      "13 6 ['Marketable securities', '98,793', '', '\\xa0', '105,341', '']\n",
      "14 6 ['Property, plant and equipment, net', '35,889', '', '\\xa0', '37,378', '']\n",
      "15 6 ['Other non-current assets', '41,965', '', '\\xa0', '32,978', '']\n",
      "16 6 ['Total non-current assets', '176,647', '', '\\xa0', '175,697', '']\n",
      "17 8 ['Total assets', '$', '320,400', '', '\\xa0', '$', '338,516', '']\n",
      "18 4 ['\\xa0', '\\xa0', '\\xa0', '\\xa0']\n",
      "19 1 ['LIABILITIES AND SHAREHOLDERS’ EQUITY:']\n",
      "20 4 ['Current liabilities:', '\\xa0', '\\xa0', '\\xa0']\n",
      "21 8 ['Accounts payable', '$', '32,421', '', '\\xa0', '$', '46,236', '']\n",
      "22 6 ['Other current liabilities', '37,324', '', '\\xa0', '37,720', '']\n",
      "23 6 ['Deferred revenue', '5,928', '', '\\xa0', '5,522', '']\n",
      "24 6 ['Commercial paper and repurchase agreement', '10,029', '', '\\xa0', '5,980', '']\n",
      "25 6 ['Term debt', '10,392', '', '\\xa0', '10,260', '']\n",
      "26 6 ['Total current liabilities', '96,094', '', '\\xa0', '105,718', '']\n",
      "27 4 ['\\xa0', '\\xa0', '\\xa0', '\\xa0']\n",
      "28 4 ['Non-current liabilities:', '\\xa0', '\\xa0', '\\xa0']\n",
      "29 6 ['Term debt', '89,086', '', '\\xa0', '91,807', '']\n",
      "30 6 ['Other non-current liabilities', '56,795', '', '\\xa0', '50,503', '']\n",
      "31 6 ['Total non-current liabilities', '145,881', '', '\\xa0', '142,310', '']\n",
      "32 6 ['Total liabilities', '241,975', '', '\\xa0', '248,028', '']\n",
      "33 4 ['\\xa0', '\\xa0', '\\xa0', '\\xa0']\n",
      "34 4 ['Commitments and contingencies', '', '\\xa0', '']\n",
      "35 4 ['\\xa0', '\\xa0', '\\xa0', '\\xa0']\n",
      "36 4 ['Shareholders’ equity:', '\\xa0', '\\xa0', '\\xa0']\n",
      "37 6 ['Common stock and additional paid-in capital, $0.00001 par value: 12,600,000 shares authorized; 4,323,987 and 4,443,236 shares issued and outstanding, respectively', '48,032', '', '\\xa0', '45,174', '']\n",
      "38 6 ['Retained earnings', '33,182', '', '\\xa0', '45,898', '']\n",
      "39 6 ['Accumulated other comprehensive income/(loss)', '(2,789', ')', '\\xa0', '(584', ')']\n",
      "40 6 ['Total shareholders’ equity', '78,425', '', '\\xa0', '90,488', '']\n",
      "41 8 ['Total liabilities and shareholders’ equity', '$', '320,400', '', '\\xa0', '$', '338,516', '']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>ASSETS:</th>\n",
       "      <th>Current assets:</th>\n",
       "      <th>Cash and cash equivalents</th>\n",
       "      <th>Marketable securities</th>\n",
       "      <th>Accounts receivable</th>\n",
       "      <th>Inventories</th>\n",
       "      <th>Vendor non-trade receivables</th>\n",
       "      <th>Other current assets</th>\n",
       "      <th>Total current assets</th>\n",
       "      <th></th>\n",
       "      <th>Non-current assets:</th>\n",
       "      <th>Marketable securities</th>\n",
       "      <th>Property, plant and equipment, net</th>\n",
       "      <th>Other non-current assets</th>\n",
       "      <th>Total non-current assets</th>\n",
       "      <th>Total assets</th>\n",
       "      <th></th>\n",
       "      <th>LIABILITIES AND SHAREHOLDERS’ EQUITY:</th>\n",
       "      <th>Current liabilities:</th>\n",
       "      <th>Accounts payable</th>\n",
       "      <th>Other current liabilities</th>\n",
       "      <th>Deferred Revenue</th>\n",
       "      <th>Commercial paper and repurchase agreement</th>\n",
       "      <th>Term debt</th>\n",
       "      <th>Total current liabilities</th>\n",
       "      <th></th>\n",
       "      <th>Non-current liabilities:</th>\n",
       "      <th>Term debt</th>\n",
       "      <th>Other non-current liabilities</th>\n",
       "      <th>Total non-current liabilities</th>\n",
       "      <th>Total liabilities</th>\n",
       "      <th></th>\n",
       "      <th>Commitments and contingencies</th>\n",
       "      <th></th>\n",
       "      <th>Shareholders’ equity:</th>\n",
       "      <th>Common Stock</th>\n",
       "      <th>Retained earnings</th>\n",
       "      <th>Accumulated other comprehensive income/(loss)</th>\n",
       "      <th>Total shareholders’ equity</th>\n",
       "      <th>Total liabilities and shareholders’ equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Q1</td>\n",
       "      <td>2020</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>40174000</td>\n",
       "      <td>53877000</td>\n",
       "      <td>15722000</td>\n",
       "      <td>3334000</td>\n",
       "      <td>14955000</td>\n",
       "      <td>15691000</td>\n",
       "      <td>143753000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>98793000</td>\n",
       "      <td>35889000</td>\n",
       "      <td>41965000</td>\n",
       "      <td>176647000</td>\n",
       "      <td>320400000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>32421000</td>\n",
       "      <td>37324000</td>\n",
       "      <td>5928000</td>\n",
       "      <td>10029000</td>\n",
       "      <td>10392000</td>\n",
       "      <td>96094000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>89086000</td>\n",
       "      <td>56795000</td>\n",
       "      <td>145881000</td>\n",
       "      <td>241975000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>48032000</td>\n",
       "      <td>33182000</td>\n",
       "      <td>2789000</td>\n",
       "      <td>78425000</td>\n",
       "      <td>320400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 Quarter  Year ASSETS: Current assets: Cash and cash equivalents  \\\n",
       "0      Q1  2020    None            None                  40174000   \n",
       "\n",
       "0 Marketable securities Accounts receivable Inventories  \\\n",
       "0              53877000            15722000     3334000   \n",
       "\n",
       "0 Vendor non-trade receivables Other current assets Total current assets  \\\n",
       "0                     14955000             15691000            143753000   \n",
       "\n",
       "0       Non-current assets: Marketable securities  \\\n",
       "0  None                None              98793000   \n",
       "\n",
       "0 Property, plant and equipment, net Other non-current assets  \\\n",
       "0                           35889000                 41965000   \n",
       "\n",
       "0 Total non-current assets Total assets        \\\n",
       "0                176647000    320400000  None   \n",
       "\n",
       "0 LIABILITIES AND SHAREHOLDERS’ EQUITY: Current liabilities: Accounts payable  \\\n",
       "0                                  None                 None         32421000   \n",
       "\n",
       "0 Other current liabilities Deferred Revenue  \\\n",
       "0                  37324000          5928000   \n",
       "\n",
       "0 Commercial paper and repurchase agreement Term debt  \\\n",
       "0                                  10029000  10392000   \n",
       "\n",
       "0 Total current liabilities       Non-current liabilities: Term debt  \\\n",
       "0                  96094000  None                     None  89086000   \n",
       "\n",
       "0 Other non-current liabilities Total non-current liabilities  \\\n",
       "0                      56795000                     145881000   \n",
       "\n",
       "0 Total liabilities       Commitments and contingencies        \\\n",
       "0         241975000  None                          None  None   \n",
       "\n",
       "0 Shareholders’ equity: Common Stock Retained earnings  \\\n",
       "0                  None     48032000          33182000   \n",
       "\n",
       "0 Accumulated other comprehensive income/(loss) Total shareholders’ equity  \\\n",
       "0                                       2789000                   78425000   \n",
       "\n",
       "0 Total liabilities and shareholders’ equity  \n",
       "0                                  320400000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "string_test = master_filings_dict['0000320193-20-000052']['filing_documents']['10-Q']['pages_code']\n",
    "test_df = table(string_test, '10-Q')\n",
    "table_df = test_df[0].drop([2]).reset_index(drop=True)\n",
    "ICD.display(table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>ASSETS:</th>\n",
       "      <th>Current assets:</th>\n",
       "      <th>Cash and cash equivalents</th>\n",
       "      <th>Marketable securities</th>\n",
       "      <th>Accounts receivable</th>\n",
       "      <th>Inventories</th>\n",
       "      <th>Vendor non-trade receivables</th>\n",
       "      <th>Other current assets</th>\n",
       "      <th>Total current assets</th>\n",
       "      <th></th>\n",
       "      <th>Non-current assets:</th>\n",
       "      <th>Marketable securities</th>\n",
       "      <th>Property, plant and equipment, net</th>\n",
       "      <th>Other non-current assets</th>\n",
       "      <th>Total non-current assets</th>\n",
       "      <th>Total assets</th>\n",
       "      <th></th>\n",
       "      <th>LIABILITIES AND SHAREHOLDERS’ EQUITY:</th>\n",
       "      <th>Current liabilities:</th>\n",
       "      <th>Accounts payable</th>\n",
       "      <th>Other current liabilities</th>\n",
       "      <th>Deferred Revenue</th>\n",
       "      <th>Commercial paper and repurchase agreement</th>\n",
       "      <th>Term debt</th>\n",
       "      <th>Total current liabilities</th>\n",
       "      <th></th>\n",
       "      <th>Non-current liabilities:</th>\n",
       "      <th>Term debt</th>\n",
       "      <th>Other non-current liabilities</th>\n",
       "      <th>Total non-current liabilities</th>\n",
       "      <th>Total liabilities</th>\n",
       "      <th></th>\n",
       "      <th>Commitments and contingencies</th>\n",
       "      <th></th>\n",
       "      <th>Shareholders’ equity:</th>\n",
       "      <th>Common Stock</th>\n",
       "      <th>Retained earnings</th>\n",
       "      <th>Accumulated other comprehensive income/(loss)</th>\n",
       "      <th>Total shareholders’ equity</th>\n",
       "      <th>Total liabilities and shareholders’ equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Q1</td>\n",
       "      <td>2020</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>40174000</td>\n",
       "      <td>53877000</td>\n",
       "      <td>15722000</td>\n",
       "      <td>3334000</td>\n",
       "      <td>14955000</td>\n",
       "      <td>15691000</td>\n",
       "      <td>143753000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>98793000</td>\n",
       "      <td>35889000</td>\n",
       "      <td>41965000</td>\n",
       "      <td>176647000</td>\n",
       "      <td>320400000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>32421000</td>\n",
       "      <td>37324000</td>\n",
       "      <td>5928000</td>\n",
       "      <td>10029000</td>\n",
       "      <td>10392000</td>\n",
       "      <td>96094000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>89086000</td>\n",
       "      <td>56795000</td>\n",
       "      <td>145881000</td>\n",
       "      <td>241975000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>48032000</td>\n",
       "      <td>33182000</td>\n",
       "      <td>2789000</td>\n",
       "      <td>78425000</td>\n",
       "      <td>320400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8844e+07</td>\n",
       "      <td>5.1713e+07</td>\n",
       "      <td>2.2926e+07</td>\n",
       "      <td>4.106e+06</td>\n",
       "      <td>2.2878e+07</td>\n",
       "      <td>1.2352e+07</td>\n",
       "      <td>1.62819e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.05341e+08</td>\n",
       "      <td>3.7378e+07</td>\n",
       "      <td>3.2978e+07</td>\n",
       "      <td>1.75697e+08</td>\n",
       "      <td>3.38516e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.6236e+07</td>\n",
       "      <td>3.772e+07</td>\n",
       "      <td>5.522e+06</td>\n",
       "      <td>5.98e+06</td>\n",
       "      <td>1.026e+07</td>\n",
       "      <td>1.05718e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.1807e+07</td>\n",
       "      <td>5.0503e+07</td>\n",
       "      <td>1.4231e+08</td>\n",
       "      <td>2.48028e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5174e+07</td>\n",
       "      <td>4.5898e+07</td>\n",
       "      <td>584000</td>\n",
       "      <td>9.0488e+07</td>\n",
       "      <td>3.38516e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 Quarter  Year ASSETS: Current assets: Cash and cash equivalents  \\\n",
       "1      Q1  2020    None            None                  40174000   \n",
       "2     NaN   NaN     NaN             NaN                4.8844e+07   \n",
       "\n",
       "0 Marketable securities Accounts receivable Inventories  \\\n",
       "1              53877000            15722000     3334000   \n",
       "2            5.1713e+07          2.2926e+07   4.106e+06   \n",
       "\n",
       "0 Vendor non-trade receivables Other current assets Total current assets  \\\n",
       "1                     14955000             15691000            143753000   \n",
       "2                   2.2878e+07           1.2352e+07          1.62819e+08   \n",
       "\n",
       "0       Non-current assets: Marketable securities  \\\n",
       "1  None                None              98793000   \n",
       "2   NaN                 NaN           1.05341e+08   \n",
       "\n",
       "0 Property, plant and equipment, net Other non-current assets  \\\n",
       "1                           35889000                 41965000   \n",
       "2                         3.7378e+07               3.2978e+07   \n",
       "\n",
       "0 Total non-current assets Total assets        \\\n",
       "1                176647000    320400000  None   \n",
       "2              1.75697e+08  3.38516e+08   NaN   \n",
       "\n",
       "0 LIABILITIES AND SHAREHOLDERS’ EQUITY: Current liabilities: Accounts payable  \\\n",
       "1                                  None                 None         32421000   \n",
       "2                                   NaN                  NaN       4.6236e+07   \n",
       "\n",
       "0 Other current liabilities Deferred Revenue  \\\n",
       "1                  37324000          5928000   \n",
       "2                 3.772e+07        5.522e+06   \n",
       "\n",
       "0 Commercial paper and repurchase agreement  Term debt  \\\n",
       "1                                  10029000   10392000   \n",
       "2                                  5.98e+06  1.026e+07   \n",
       "\n",
       "0 Total current liabilities       Non-current liabilities:   Term debt  \\\n",
       "1                  96094000  None                     None    89086000   \n",
       "2               1.05718e+08   NaN                      NaN  9.1807e+07   \n",
       "\n",
       "0 Other non-current liabilities Total non-current liabilities  \\\n",
       "1                      56795000                     145881000   \n",
       "2                    5.0503e+07                    1.4231e+08   \n",
       "\n",
       "0 Total liabilities       Commitments and contingencies        \\\n",
       "1         241975000  None                          None  None   \n",
       "2       2.48028e+08   NaN                           NaN   NaN   \n",
       "\n",
       "0 Shareholders’ equity: Common Stock Retained earnings  \\\n",
       "1                  None     48032000          33182000   \n",
       "2                   NaN   4.5174e+07        4.5898e+07   \n",
       "\n",
       "0 Accumulated other comprehensive income/(loss) Total shareholders’ equity  \\\n",
       "1                                       2789000                   78425000   \n",
       "2                                        584000                 9.0488e+07   \n",
       "\n",
       "0 Total liabilities and shareholders’ equity  \n",
       "1                                  320400000  \n",
       "2                                3.38516e+08  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print( len(test_df[0].columns) )\n",
    "ICD.display(test_df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Files Locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the pages from 10-Q document 0000320193-20-000052 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0000320193-20-000010 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0000320193-19-000076 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0000320193-19-000066 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0000320193-19-000010 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0000320193-18-000100 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0000320193-18-000070 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0000320193-18-000007 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0000320193-17-000009 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0001628280-17-004790 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0001628280-17-000717 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0001628280-16-017809 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0001193125-16-559625 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0001193125-16-439878 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0001193125-15-259935 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0001193125-15-153166 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0001193125-15-023697 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0001193125-14-277160 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0001193125-14-157311 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-Q document 0001193125-14-024487 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-K document 0000320193-19-000119 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-K document 0000320193-18-000145 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-K document 0000320193-17-000070 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-K document 0001628280-16-020309 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "All the pages from 10-K document 0001193125-15-356351 have been tableized and saved.\n",
      "--------------------------------------------------------------------------------\n",
      "Something went wrong in file 0001193125-14-383437, file type = 10-K\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Checklist = {}\n",
    "\n",
    "for k, v in QorK.items():\n",
    "    value_list = []\n",
    "    for i, vv in enumerate(v):\n",
    "\n",
    "        # first grab 10-Q documents only\n",
    "        pages = master_filings_dict[v[i]]['filing_documents'][k]['pages_code']\n",
    "\n",
    "        try:\n",
    "            # Extract Table from html code and wrap it as a list of df.\n",
    "            table_df = table(pages, k)                 \n",
    "            #ICD.display(table_df[0])\n",
    "\n",
    "            with open('{}-{}.csv'.format(v[i], k), \"wb\") as fp:   # Pickling\n",
    "                pickle.dump(table_df, fp)\n",
    "\n",
    "            # display a status to the user.\n",
    "            print('All the pages from {} document {} have been tableized and saved.'.format(k, v[i]))\n",
    "        \n",
    "        except: \n",
    "            value_list.append(vv)\n",
    "            print('Something went wrong in file {}, file type = {}'.format(v[i], k))\n",
    "        \n",
    "        print('-'*80) \n",
    "    Checklist['{}'.format(k)] = value_list\n",
    "    del value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10-Q': [], '10-K': ['0001193125-14-383437']}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the Old and the New."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample: Older filing style. \n",
    "import pickle\n",
    "pd.set_option('display.max_columns', 100)\n",
    "with open(\"0001564590-19-038256-10-Q.csv\", \"rb\") as fp:\n",
    "    file = pickle.load(fp)\n",
    "df01 = file[0]\n",
    "\n",
    "# df01['CSN_SUM'] = df01['Convertible Senior Notes'].values.sum()\n",
    "# del df01['Convertible Senior Notes']\n",
    "\n",
    "# df01['DeferredRevenue'] = df01['Deferred Revenue'].values.sum()\n",
    "# del df01['Deferred Revenue']\n",
    "\n",
    "# df01['NoncontrollingInterests'] = df01['Noncontrolling interests in subsidiaries'].values.sum()\n",
    "# del df01['Noncontrolling interests in subsidiaries']\n",
    "\n",
    "print(df01.shape)\n",
    "df01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_columns( df01 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newer Filing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample: Newer filing style. \n",
    "import pickle \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "with open(\"0001564590-20-019931-10-Q.csv\", \"rb\") as fp:\n",
    "    file = pickle.load(fp)\n",
    "df02 = file[0]\n",
    "print(df02.shape) \n",
    "df02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_duplicate_columns( df02 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using the Function')\n",
    "\n",
    "duplicate_columns( df02 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slamming the Raw DataFrame into the dissected column cleanser. \n",
    "print('Not Using the Function')\n",
    "duplicates = [k for (k,v) in Counter(df02.columns).items() if v > 1] \n",
    "\n",
    "for dupli in duplicates: \n",
    "    res = df02[dupli].values.sum()\n",
    "    df02['Total {}'.format(dupli)] = res\n",
    "    df02.drop(dupli, axis=1, inplace=True)\n",
    "    \n",
    "df02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate col_name, add column tgt.\n",
    "df2 = df02.copy()\n",
    "\n",
    "# df2['CSN_SUM'] = df2['Convertible Senior Notes'].values.sum()\n",
    "# del df2['Convertible Senior Notes']\n",
    "\n",
    "df2['DeferredRevenue'] = df2['Deferred Revenue'].values.sum()\n",
    "del df2['Deferred Revenue']\n",
    "\n",
    "df2['NoncontrollingInterests'] = df2['Noncontrolling interests in subsidiaries'].values.sum()\n",
    "del df2['Noncontrolling interests in subsidiaries']\n",
    "\n",
    "#df2.set_index(['Year', 'Quarter'], inplace=True)\n",
    "\n",
    "print( df2.shape )\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_duplicate_columns( df2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concating dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_ = pd.concat([df2, df01], axis=0, sort=False)\n",
    "\n",
    "print(c_.shape)\n",
    "c_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serious Stuff. \n",
    "def duplicate_columns( DataF ):\n",
    "    \n",
    "    duplicates = [k for (k,v) in Counter(DataF.columns).items() if v > 1] \n",
    "\n",
    "    for dupli in duplicates: \n",
    "        \n",
    "        res = DataF[dupli].values.sum()\n",
    "        \n",
    "        DataF['Serious {}'.format(dupli)] = res\n",
    "        \n",
    "        DataF.drop(dupli, axis=1, inplace=True)\n",
    "\n",
    "    return DataF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for checking.\n",
    "def checking_duplicate_columns( DataF ):\n",
    "    \n",
    "    duplicates = [k for (k,v) in Counter(DataF.columns).items() if v > 1] \n",
    "\n",
    "    \n",
    "    print('Shape of df: ', DataF.shape )\n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_.set_index(['Year', 'Quarter'], inplace=True)\n",
    "print(c_.shape)\n",
    "c_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c1 = c_.copy()\n",
    "c1.dropna( axis= 1, inplace=True)\n",
    "print(c1.shape)\n",
    "c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "QorK = {\n",
    "    '10-Q': ['0001564590-20-019931', '0001564590-19-038256', '0001564590-19-026445', '0001564590-19-013462', '0001564590-18-026353', '0001564590-18-019254', '0001564590-18-011086', '0001564590-17-021343', '0001564590-17-015705', '0001564590-17-009968', '0001564590-16-026820', '0001564590-16-023024', '0001564590-16-018886', '0001564590-15-009741', '0001564590-15-006666', '0001564590-15-003789'],\n",
    "    '10-K': ['0001564590-20-004475', '0001564590-19-003165', '0001564590-18-002956', '0001564590-17-003118', '0001564590-16-013195', '0001564590-15-001031']}\n",
    "QorK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concating all Balance Sheet together.\n",
    "\n",
    "for k, v in QorK.items():\n",
    "    \n",
    "    #if k == '10-Q' and v == '0001564590-17-009968':\n",
    "        \n",
    "        for i, vv in enumerate(v):\n",
    "\n",
    "            # first grab 10-Q documents only\n",
    "            pages = master_filings_dict[v[i]]['filing_documents'][k]['pages_code']\n",
    "\n",
    "            try:\n",
    "                # Extract Table from html code and wrap it as a list of df.\n",
    "                table_df = table(pages)                 \n",
    "\n",
    "            except: \n",
    "                print('Something went wrong in file {}, file type = {}'.format(v[i], k))\n",
    "\n",
    "            with open('{}-{}.csv'.format(v[i], k), \"wb\") as fp:   # Pickling\n",
    "                pickle.dump(table_df, fp)\n",
    "                \n",
    "                  \n",
    "pd.set_option('display.max_columns', 100)\n",
    "with open(\"0001564590-15-001031-10-K.csv\", \"rb\") as fp:\n",
    "    file = pickle.load(fp)\n",
    "df1 = file[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statement Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BS10_K(df)\n",
    "    \n",
    "    missing_values = [ '\\n', None, '\\n—', '\\n0', '\\n$', '\\n()']\n",
    "    \n",
    "    # Clean df.\n",
    "    df = df.drop([1,4,5,6,7,8], axis=1, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CF10_K(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoO10_K(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BS10_Q(table):\n",
    "    \n",
    "    BSdf = []\n",
    "    missing_values = [ '\\n', None, '\\n—', '\\n0', '\\n$', '\\n()']\n",
    "    \n",
    "    # Clean the table. \n",
    "    \n",
    "    row = table.replace(missing_values, '', regex=True)\n",
    "    file = file.drop(axis=1, columns = [1,4:], inplace=True)\n",
    "\n",
    "    statement = BSddf.DataFrame(row)\n",
    "    BSdf.append(statement)\n",
    "    \n",
    "    return BSdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CF10_Q(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_table = []\n",
    "for table_num, table in enumerate(file):\n",
    "    \n",
    "    if table_num > 1:\n",
    "        print(table_num)\n",
    "        cleaned_row = cleaning_row(table)\n",
    "\n",
    "        res_table.append(cleaned_row)\n",
    "\n",
    "print(res_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Statment specific files for \n",
    "TSLA_BS10_K = []\n",
    "TSLA_CF10_K = []\n",
    "TSLA_SoO10_K = []\n",
    "TSLA_BS10_Q = []\n",
    "TSLA_CF10_Q = []\n",
    "TSLA_SoO10_Q = []\n",
    "\n",
    "for k, v in QorK.items():\n",
    "    \n",
    "    if k == '10-K':\n",
    "        \n",
    "        for i in range(len(v)):\n",
    "            \n",
    "    if k == '10-Q'\n",
    "    \n",
    "        for i in range(len(v)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/50950614/converting-column-into-multi-index-column"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
