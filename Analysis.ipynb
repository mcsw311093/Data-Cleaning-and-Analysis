{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open this notebook in nbviewer to use the links. http://jiffyclub.github.io/open-in-nbviewer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "Electric vehicle (EV) manufacturer, Tesla, has been seen as a disruptive force in the auto-industry<sup>1</sup>. \n",
    "Indeed such growth is likened to the tech industry or even comparable to an entirely new industry<sup>2</sup>.<br />  \n",
    "By comparing quarterly balance sheets from US-based auto and tech companies over the past thirteen years, we explore if there is evidence from an asset-and-liabilities perspective to support such claims. \n",
    "\n",
    "\n",
    "<sup>1</sup>https://www.businessinsider.com/tesla-stock-value-compared-ford-gm-fca-car-production-charts-2020-7<br />\n",
    "<sup>2</sup>https://www.investopedia.com/news/tesla-tech-company-or-car-company/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'><a/>\n",
    "# Table of Contents\n",
    "#### 1) Transforming time series data into de-trended, scaled and normalised format (i.i.d.) for tabular classification. \n",
    "    \n",
    "   [Experiment 1.1 - grouping all companies as a whole for one transformation.](#expt1.1)\n",
    "    \n",
    "   [Pipeline and Hyperparameter Tuning](#pipe&Hyper)\n",
    "    \n",
    "   [Experiment 2.2 - individually transforming within companies across the same time-frame](#expt1.2)\n",
    "\n",
    "#### 2) Use Statistics \n",
    "   [Experiment 2.1 - MANOVA](#expt2.1)\n",
    "    \n",
    "#### 3) Use Cluster Analysis \n",
    "   [Experiment 3.1 - k-means](#expt3.1)\n",
    "    \n",
    "#### 4) Use Sktime\n",
    "   [Experiment 4.1 - ML Time Series Analysis](#expt4.1)\n",
    "\n",
    "   [Appendix](#appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "Data was manually collected first hand from the SEC website.<br />\n",
    "The whole process of data-cleaning can be found in [Data-Cleaning.ipynb](https://github.com/mcsw311093/Data-Cleaning-and-Analysis/blob/master/Creating%20ABT.ipynb) of the current repo.<br />\n",
    "See my [web_scraping_sec](https://github.com/mcsw311093/web_scraping_sec) repo for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim and Motivation (Introduction)\n",
    "All comparisons are\n",
    "ML and Statistics approach to solve 2 problems: \n",
    "1) Test Assumption: Auto-industry != Tech-industry "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframe and libraries\n",
    "import pandas as pd\n",
    "import numpy as np, array\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Function for creating model pipelines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Import Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import RandomForestClassifier and GradientBoostingClassifer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Function for splitting training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classification metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns \n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.core import display as ICD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power Transform\n",
    "from sklearn.preprocessing import power_transform\n",
    "\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import yeojohnson\n",
    "\n",
    "# Difference computation function\n",
    "def difference(data, interval):\n",
    "    return [data[i] - data[i - interval] for i in range(interval, len(data))]\n",
    "\n",
    "# StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('abt.csv')\n",
    "main_df.set_index(['Year', 'Quarter'], drop=True, inplace=True)\n",
    "main_df.sort_index(ascending=True, sort_remaining= True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accounts Receivable</th>\n",
       "      <th>Inventory</th>\n",
       "      <th>Total current assets</th>\n",
       "      <th>Total current liabilities</th>\n",
       "      <th>Total liabilities</th>\n",
       "      <th>Common Stock</th>\n",
       "      <th>Total liabilities and equity</th>\n",
       "      <th>New Deferred Revenue</th>\n",
       "      <th>New Property and Equipment</th>\n",
       "      <th>Total Non-Current Assets</th>\n",
       "      <th>Total_Assets</th>\n",
       "      <th>Non-Current Liabilities</th>\n",
       "      <th>Total Shareholder's Equity</th>\n",
       "      <th>Accounts Payables</th>\n",
       "      <th>Retained Earning</th>\n",
       "      <th>OCI</th>\n",
       "      <th>Accounts_Receivable_missing</th>\n",
       "      <th>Common_Stock_missing</th>\n",
       "      <th>Short_term_investments</th>\n",
       "      <th>Short_term_investments_missing</th>\n",
       "      <th>Inventory_missing</th>\n",
       "      <th>current_ratio</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>debt_to_equity_ratio</th>\n",
       "      <th>equity_multiplier</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Amazon</td>\n",
       "      <td>2.829430e+11</td>\n",
       "      <td>3.825570e+11</td>\n",
       "      <td>1.428235e+12</td>\n",
       "      <td>1.301270e+12</td>\n",
       "      <td>2.219730e+12</td>\n",
       "      <td>2.410000e+08</td>\n",
       "      <td>3044300000000</td>\n",
       "      <td>1.271290e+11</td>\n",
       "      <td>1.046805e+12</td>\n",
       "      <td>2.108220e+11</td>\n",
       "      <td>3.044300e+12</td>\n",
       "      <td>9.184600e+11</td>\n",
       "      <td>8.245700e+11</td>\n",
       "      <td>7.327650e+11</td>\n",
       "      <td>2.964710e+11</td>\n",
       "      <td>2.222100e+10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.756270e+11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.065070</td>\n",
       "      <td>42.640448</td>\n",
       "      <td>34.963018</td>\n",
       "      <td>130.548865</td>\n",
       "      <td>180.548865</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Apple</td>\n",
       "      <td>3.975220e+11</td>\n",
       "      <td>8.578300e+10</td>\n",
       "      <td>2.800189e+12</td>\n",
       "      <td>2.125556e+12</td>\n",
       "      <td>5.016973e+12</td>\n",
       "      <td>8.655780e+11</td>\n",
       "      <td>8110972000000</td>\n",
       "      <td>2.627400e+11</td>\n",
       "      <td>7.421370e+11</td>\n",
       "      <td>1.740391e+12</td>\n",
       "      <td>8.110972e+12</td>\n",
       "      <td>2.184731e+12</td>\n",
       "      <td>3.093999e+12</td>\n",
       "      <td>9.117180e+11</td>\n",
       "      <td>2.245244e+12</td>\n",
       "      <td>3.245900e+10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.774262e+12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>34.278200</td>\n",
       "      <td>33.245377</td>\n",
       "      <td>15.750090</td>\n",
       "      <td>43.698300</td>\n",
       "      <td>69.698300</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Facebook</td>\n",
       "      <td>1.021680e+11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.812530e+11</td>\n",
       "      <td>1.201380e+11</td>\n",
       "      <td>2.715360e+11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1752395000000</td>\n",
       "      <td>2.474000e+09</td>\n",
       "      <td>3.430340e+11</td>\n",
       "      <td>8.617100e+10</td>\n",
       "      <td>1.752395e+12</td>\n",
       "      <td>1.097640e+11</td>\n",
       "      <td>2.789311e+12</td>\n",
       "      <td>9.619000e+09</td>\n",
       "      <td>6.261750e+11</td>\n",
       "      <td>1.067900e+10</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>5.449710e+11</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>209.655930</td>\n",
       "      <td>209.655930</td>\n",
       "      <td>3.006712</td>\n",
       "      <td>1.913864</td>\n",
       "      <td>13.727506</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ford</td>\n",
       "      <td>4.271477e+12</td>\n",
       "      <td>3.004110e+11</td>\n",
       "      <td>3.144905e+12</td>\n",
       "      <td>2.622717e+12</td>\n",
       "      <td>6.070087e+12</td>\n",
       "      <td>1.188000e+09</td>\n",
       "      <td>6941199000000</td>\n",
       "      <td>1.209010e+12</td>\n",
       "      <td>9.493500e+11</td>\n",
       "      <td>3.796294e+12</td>\n",
       "      <td>6.941199e+12</td>\n",
       "      <td>1.301248e+12</td>\n",
       "      <td>8.665520e+11</td>\n",
       "      <td>6.549910e+11</td>\n",
       "      <td>6.151340e+11</td>\n",
       "      <td>3.666120e+11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.122080e+11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.919542</td>\n",
       "      <td>32.394452</td>\n",
       "      <td>26.276471</td>\n",
       "      <td>217.926688</td>\n",
       "      <td>248.112358</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GM</td>\n",
       "      <td>1.644996e+12</td>\n",
       "      <td>5.700550e+11</td>\n",
       "      <td>3.200108e+12</td>\n",
       "      <td>2.963690e+12</td>\n",
       "      <td>6.241944e+12</td>\n",
       "      <td>5.930000e+08</td>\n",
       "      <td>7959308000000</td>\n",
       "      <td>1.268860e+12</td>\n",
       "      <td>2.115283e+12</td>\n",
       "      <td>4.846485e+12</td>\n",
       "      <td>7.959308e+12</td>\n",
       "      <td>3.278254e+12</td>\n",
       "      <td>1.627338e+12</td>\n",
       "      <td>1.051662e+12</td>\n",
       "      <td>6.460360e+11</td>\n",
       "      <td>2.701340e+11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.161520e+11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.476217</td>\n",
       "      <td>38.794746</td>\n",
       "      <td>33.521496</td>\n",
       "      <td>168.980508</td>\n",
       "      <td>214.518253</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Google</td>\n",
       "      <td>3.111810e+11</td>\n",
       "      <td>1.197800e+10</td>\n",
       "      <td>2.279091e+12</td>\n",
       "      <td>5.004500e+11</td>\n",
       "      <td>8.594560e+11</td>\n",
       "      <td>7.801800e+11</td>\n",
       "      <td>3849115000000</td>\n",
       "      <td>3.170500e+10</td>\n",
       "      <td>9.026310e+11</td>\n",
       "      <td>5.296800e+10</td>\n",
       "      <td>3.849115e+12</td>\n",
       "      <td>6.940200e+10</td>\n",
       "      <td>3.010023e+12</td>\n",
       "      <td>5.818300e+10</td>\n",
       "      <td>2.257396e+12</td>\n",
       "      <td>2.755300e+10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.583755e+12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>93.089222</td>\n",
       "      <td>92.671373</td>\n",
       "      <td>4.140259</td>\n",
       "      <td>5.295098</td>\n",
       "      <td>24.123270</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Microsoft</td>\n",
       "      <td>5.313600e+11</td>\n",
       "      <td>7.394500e+10</td>\n",
       "      <td>4.296721e+12</td>\n",
       "      <td>1.558512e+12</td>\n",
       "      <td>3.847046e+12</td>\n",
       "      <td>2.248386e+12</td>\n",
       "      <td>6524922000000</td>\n",
       "      <td>8.558170e+11</td>\n",
       "      <td>6.628030e+11</td>\n",
       "      <td>3.780890e+11</td>\n",
       "      <td>6.524922e+12</td>\n",
       "      <td>1.406331e+12</td>\n",
       "      <td>2.677876e+12</td>\n",
       "      <td>2.150510e+11</td>\n",
       "      <td>3.924650e+11</td>\n",
       "      <td>5.902300e+10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.214832e+12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88.989467</td>\n",
       "      <td>87.415692</td>\n",
       "      <td>18.176794</td>\n",
       "      <td>46.010661</td>\n",
       "      <td>78.010661</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Netflix</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.930012e+13</td>\n",
       "      <td>4.731783e+13</td>\n",
       "      <td>3.558797e+13</td>\n",
       "      <td>9.812288e+13</td>\n",
       "      <td>9.938387e+12</td>\n",
       "      <td>124929670160000</td>\n",
       "      <td>4.226629e+12</td>\n",
       "      <td>2.671635e+12</td>\n",
       "      <td>5.674708e+12</td>\n",
       "      <td>1.249297e+14</td>\n",
       "      <td>2.205699e+12</td>\n",
       "      <td>2.680679e+13</td>\n",
       "      <td>2.984036e+12</td>\n",
       "      <td>1.438237e+13</td>\n",
       "      <td>1.688469e+11</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>3.380962e+12</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>66.778027</td>\n",
       "      <td>-5.657607</td>\n",
       "      <td>35.801000</td>\n",
       "      <td>158.649349</td>\n",
       "      <td>206.649349</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tesla</td>\n",
       "      <td>1.344071e+10</td>\n",
       "      <td>5.293356e+10</td>\n",
       "      <td>1.465474e+11</td>\n",
       "      <td>1.450426e+11</td>\n",
       "      <td>3.730633e+11</td>\n",
       "      <td>2.932000e+06</td>\n",
       "      <td>477577304000</td>\n",
       "      <td>3.292231e+10</td>\n",
       "      <td>1.611449e+11</td>\n",
       "      <td>1.146351e+10</td>\n",
       "      <td>4.775773e+11</td>\n",
       "      <td>1.749331e+11</td>\n",
       "      <td>8.476468e+10</td>\n",
       "      <td>4.905543e+10</td>\n",
       "      <td>8.901459e+10</td>\n",
       "      <td>9.630870e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.792980e+08</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>23.363573</td>\n",
       "      <td>14.832870</td>\n",
       "      <td>17.539468</td>\n",
       "      <td>108.706417</td>\n",
       "      <td>134.864269</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Accounts Receivable     Inventory  Total current assets  \\\n",
       "company_name                                                            \n",
       "Amazon               2.829430e+11  3.825570e+11          1.428235e+12   \n",
       "Apple                3.975220e+11  8.578300e+10          2.800189e+12   \n",
       "Facebook             1.021680e+11  0.000000e+00          8.812530e+11   \n",
       "Ford                 4.271477e+12  3.004110e+11          3.144905e+12   \n",
       "GM                   1.644996e+12  5.700550e+11          3.200108e+12   \n",
       "Google               3.111810e+11  1.197800e+10          2.279091e+12   \n",
       "Microsoft            5.313600e+11  7.394500e+10          4.296721e+12   \n",
       "Netflix              0.000000e+00  8.930012e+13          4.731783e+13   \n",
       "Tesla                1.344071e+10  5.293356e+10          1.465474e+11   \n",
       "\n",
       "              Total current liabilities  Total liabilities  Common Stock  \\\n",
       "company_name                                                               \n",
       "Amazon                     1.301270e+12       2.219730e+12  2.410000e+08   \n",
       "Apple                      2.125556e+12       5.016973e+12  8.655780e+11   \n",
       "Facebook                   1.201380e+11       2.715360e+11  0.000000e+00   \n",
       "Ford                       2.622717e+12       6.070087e+12  1.188000e+09   \n",
       "GM                         2.963690e+12       6.241944e+12  5.930000e+08   \n",
       "Google                     5.004500e+11       8.594560e+11  7.801800e+11   \n",
       "Microsoft                  1.558512e+12       3.847046e+12  2.248386e+12   \n",
       "Netflix                    3.558797e+13       9.812288e+13  9.938387e+12   \n",
       "Tesla                      1.450426e+11       3.730633e+11  2.932000e+06   \n",
       "\n",
       "              Total liabilities and equity  New Deferred Revenue  \\\n",
       "company_name                                                       \n",
       "Amazon                       3044300000000          1.271290e+11   \n",
       "Apple                        8110972000000          2.627400e+11   \n",
       "Facebook                     1752395000000          2.474000e+09   \n",
       "Ford                         6941199000000          1.209010e+12   \n",
       "GM                           7959308000000          1.268860e+12   \n",
       "Google                       3849115000000          3.170500e+10   \n",
       "Microsoft                    6524922000000          8.558170e+11   \n",
       "Netflix                    124929670160000          4.226629e+12   \n",
       "Tesla                         477577304000          3.292231e+10   \n",
       "\n",
       "              New Property and Equipment  Total Non-Current Assets  \\\n",
       "company_name                                                         \n",
       "Amazon                      1.046805e+12              2.108220e+11   \n",
       "Apple                       7.421370e+11              1.740391e+12   \n",
       "Facebook                    3.430340e+11              8.617100e+10   \n",
       "Ford                        9.493500e+11              3.796294e+12   \n",
       "GM                          2.115283e+12              4.846485e+12   \n",
       "Google                      9.026310e+11              5.296800e+10   \n",
       "Microsoft                   6.628030e+11              3.780890e+11   \n",
       "Netflix                     2.671635e+12              5.674708e+12   \n",
       "Tesla                       1.611449e+11              1.146351e+10   \n",
       "\n",
       "              Total_Assets  Non-Current Liabilities  \\\n",
       "company_name                                          \n",
       "Amazon        3.044300e+12             9.184600e+11   \n",
       "Apple         8.110972e+12             2.184731e+12   \n",
       "Facebook      1.752395e+12             1.097640e+11   \n",
       "Ford          6.941199e+12             1.301248e+12   \n",
       "GM            7.959308e+12             3.278254e+12   \n",
       "Google        3.849115e+12             6.940200e+10   \n",
       "Microsoft     6.524922e+12             1.406331e+12   \n",
       "Netflix       1.249297e+14             2.205699e+12   \n",
       "Tesla         4.775773e+11             1.749331e+11   \n",
       "\n",
       "              Total Shareholder's Equity  Accounts Payables  Retained Earning  \\\n",
       "company_name                                                                    \n",
       "Amazon                      8.245700e+11       7.327650e+11      2.964710e+11   \n",
       "Apple                       3.093999e+12       9.117180e+11      2.245244e+12   \n",
       "Facebook                    2.789311e+12       9.619000e+09      6.261750e+11   \n",
       "Ford                        8.665520e+11       6.549910e+11      6.151340e+11   \n",
       "GM                          1.627338e+12       1.051662e+12      6.460360e+11   \n",
       "Google                      3.010023e+12       5.818300e+10      2.257396e+12   \n",
       "Microsoft                   2.677876e+12       2.150510e+11      3.924650e+11   \n",
       "Netflix                     2.680679e+13       2.984036e+12      1.438237e+13   \n",
       "Tesla                       8.476468e+10       4.905543e+10      8.901459e+10   \n",
       "\n",
       "                       OCI  Accounts_Receivable_missing  Common_Stock_missing  \\\n",
       "company_name                                                                    \n",
       "Amazon        2.222100e+10                            0                     0   \n",
       "Apple         3.245900e+10                            0                     0   \n",
       "Facebook      1.067900e+10                            0                    22   \n",
       "Ford          3.666120e+11                            0                     0   \n",
       "GM            2.701340e+11                            0                     2   \n",
       "Google        2.755300e+10                            0                     0   \n",
       "Microsoft     5.902300e+10                            0                     0   \n",
       "Netflix       1.688469e+11                           48                     0   \n",
       "Tesla         9.630870e+08                            0                     3   \n",
       "\n",
       "              Short_term_investments  Short_term_investments_missing  \\\n",
       "company_name                                                           \n",
       "Amazon                  2.756270e+11                               0   \n",
       "Apple                   3.774262e+12                               7   \n",
       "Facebook                5.449710e+11                               0   \n",
       "Ford                    6.122080e+11                               0   \n",
       "GM                      3.161520e+11                               3   \n",
       "Google                  1.583755e+12                               0   \n",
       "Microsoft               3.214832e+12                               0   \n",
       "Netflix                 3.380962e+12                              10   \n",
       "Tesla                   1.792980e+08                              14   \n",
       "\n",
       "              Inventory_missing  current_ratio  quick_ratio  debt_ratio  \\\n",
       "company_name                                                              \n",
       "Amazon                        0      59.065070    42.640448   34.963018   \n",
       "Apple                         0      34.278200    33.245377   15.750090   \n",
       "Facebook                     22     209.655930   209.655930    3.006712   \n",
       "Ford                          0      35.919542    32.394452   26.276471   \n",
       "GM                            0      47.476217    38.794746   33.521496   \n",
       "Google                        4      93.089222    92.671373    4.140259   \n",
       "Microsoft                     0      88.989467    87.415692   18.176794   \n",
       "Netflix                       1      66.778027    -5.657607   35.801000   \n",
       "Tesla                         0      23.363573    14.832870   17.539468   \n",
       "\n",
       "              debt_to_equity_ratio  equity_multiplier  industry  \n",
       "company_name                                                     \n",
       "Amazon                  130.548865         180.548865      50.0  \n",
       "Apple                    43.698300          69.698300      26.0  \n",
       "Facebook                  1.913864          13.727506      22.0  \n",
       "Ford                    217.926688         248.112358       0.0  \n",
       "GM                      168.980508         214.518253       0.0  \n",
       "Google                    5.295098          24.123270      19.0  \n",
       "Microsoft                46.010661          78.010661      32.0  \n",
       "Netflix                 158.649349         206.649349      48.0  \n",
       "Tesla                   108.706417         134.864269       0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.groupby(main_df['company_name'], sort=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Delete columns that will not be needed in Experiment 1.1.\n",
    "main_df_1_1 = main_df.copy()\n",
    "main_df_1_1.drop('Filing/Acc.No.', axis=1, inplace=True)\n",
    "main_df_1_1.drop('company_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Delete columns that will not be needed in Experiment 1.2.\n",
    "main_df_1_2 = main_df.copy()\n",
    "main_df_1_2.drop('Filing/Acc.No.', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(main_df_1_1.dtypes)\n",
    "# print(main_df_1_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A comparison of results between Scikit-Learn built-in preprocessing methods and Brown's transformation on Tesla_dataframe is provided in the appendix. Scikit-Learns methodology proved to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization\n",
    "Normality need not to be assumed, let's see how the model performs first. We will try this if the unknown pattern cannot be mapped under the current parameter settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decided to use Brown's method.\n",
    "\n",
    "Inversion would not make sense in our case since we are not predicting variables as assumed in the Brown article, and we are not comparing a model performance (predictive or classifier or otherwise). \n",
    "\n",
    "***Here transforming acheives only one goal to standardise our different companies, so that reported financials can be compared directly accross companies.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brown Article on Time-Series Data Transformation for Machine Learning - https://machinelearningmastery.com/remove-trends-seasonality-difference-transform-python/#:~:text=Stationary%20Time%20Series,-The%20observations%20in&text=Time%20series%20are%20stationary%20if,the%20variance%20of%20the%20observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brown_transform(col_name, s, window):\n",
    "    # Create a list to hold parameter information before transformation.\n",
    "    para_list = []\n",
    "    \n",
    "    # Each Series -> variable s\n",
    "    s = df[col_name]\n",
    "\n",
    "    # Power Transform\n",
    "    try:\n",
    "        result, lmbda = boxcox(s)\n",
    "#         print('box_cox')\n",
    "#         print(lmbda)\n",
    "        para_list.append(['B-C', lmbda])\n",
    "        \n",
    "    except ValueError:\n",
    "        result, lmbda = yeojohnson(s.values.reshape(-1,1))\n",
    "#         print('Yeo-Johnson')\n",
    "        \n",
    "        if type(lmbda) == np.float64:\n",
    "            para_list.append(['Y-J', lmbda])\n",
    "            \n",
    "        else:\n",
    "    #         print(f'lambda {lmbda} {type(lmbda)}')\n",
    "            lmbda = lmbda[0]\n",
    "            para_list.append(['Y-J', lmbda])\n",
    "        \n",
    "    # Difference Transform\n",
    "    diff_res = difference(result, window)\n",
    "\n",
    "    # StandardScaler\n",
    "    # Turn 1-D array of lists into a 2-D array \n",
    "    diff_res = array(diff_res).reshape(len(diff_res), 1)\n",
    "    \n",
    "    para_list.append(np.mean(diff_res))\n",
    "    para_list.append(np.std(diff_res))\n",
    "    \n",
    "    standard_res = StandardScaler().fit_transform(diff_res)\n",
    "\n",
    "    # Normalization\n",
    "#     para_list.append(min(standard_res)[0])\n",
    "#     para_list.append(max(standard_res)[0])\n",
    "    \n",
    "    norm_res = MinMaxScaler(feature_range=(1,2)).fit_transform(standard_res)\n",
    "    norm_res = [ s[0] for s in norm_res]\n",
    "    trans_para_.update({ col_name : para_list} )\n",
    "    \n",
    "    return norm_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above preprocessing steps do not require a GridSearch to optimise parameter tuning. \n",
    "\n",
    "**Power Transform:** Boxcox() automates the lambda parameter by maximising  the log likelihood function for non-negative power transformations.\n",
    "\n",
    "Since our data contains negative, zero-values, and postive values. BoxCox limitations in negative numerals is handled by Y-J; while zero values are handled by BoxCox which cannot be handled by Y-J.\n",
    "\n",
    "**Difference Transform** Utilises the value difference between t=0 and t+=interval to smooth out trends and seasonality. Since our data is quarterly based, interval = 4.\n",
    "\n",
    "**StandardScaler** Uses the mean and sd to normalise the data with zero mean and unit variance. \n",
    "\n",
    "**Normalization** Scales the data to fit with a predefined range (usually 0-1) for better comparison. \n",
    "\n",
    "Therefore, parameter tuning for preprocessing steps is unnecessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to prevent data leakage we will split the training and testing data first and apply training preprocessing parameters to the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolate Train-model-data (non-Tesla Data) from data of interest (Tesla Data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df_1_1 = main_df_1_1[main_df_1_1['industry'].isna()]\n",
    "tesla_df_1_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df_1_1 = main_df_1_1[main_df_1_1['industry'].notna()]\n",
    "Train_df_1_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate object for target variable\n",
    "y = Train_df_1_1.industry\n",
    "\n",
    "# Create separate object for input features\n",
    "X = Train_df_1_1.drop('industry', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=1234,\n",
    "                                                    stratify=Train_df_1_1.industry)\n",
    "\n",
    "# Print number of observations in X_train, X_test, y_train, and y_test\n",
    "print( len(X_train), len(X_test), len(y_train), len(y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test.sort_index(ascending=True, sort_remaining= True, inplace=True)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.sort_index(ascending=True, sort_remaining= True, inplace=True)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='expt1.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1.1 - grouping all companies as a whole for one transformation\n",
    "<a href='#top'>Top of Page</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Transforming Tech Industry training_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = X_train\n",
    "# Create dictionary to save the transformation parameters.\n",
    "trans_para_ = {}\n",
    "\n",
    "transformed_df_list = []\n",
    "\n",
    "# Apply to all training columns. \n",
    "for col_name in df.columns:\n",
    "        \n",
    "    # Apply only to numeric columns. \n",
    "    if df[col_name].dtypes == 'float64':\n",
    "            \n",
    "        s = df[col_name]\n",
    "        \n",
    "        # Brown's Transformation Suggestions\n",
    "        result = brown_transform(col_name, s, 4)\n",
    "        \n",
    "        transformed_df = pd.DataFrame({col_name:result}, index=df.index[4:] )\n",
    "        \n",
    "        transformed_df.plot(kind='line')\n",
    "        transformed_df_list.append(transformed_df)\n",
    "        \n",
    "        print(col_name)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = pd.concat(transformed_df_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the training transformations onto X_test with trans_para_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_test_new = scaler.transform(X_test)\n",
    "X_test_new_list = []\n",
    "for col, parameters in trans_para_.items():\n",
    "    \n",
    "    power_T = parameters[0][0]\n",
    "    \n",
    "    lmbda = parameters[0][1]\n",
    "    \n",
    "    mean_ = parameters[1]\n",
    "    \n",
    "    std_ = parameters[2]\n",
    "    \n",
    "    s = X_test[col]\n",
    "#     s.plot(title=col)\n",
    "#     plt.show()\n",
    "    \n",
    "    # Power Transformation\n",
    "    if power_T == 'B-C':\n",
    "        result = boxcox(s, lmbda)\n",
    "        \n",
    "    elif power_T == 'Y-J':\n",
    "        result = yeojohnson(s, lmbda)\n",
    "    \n",
    "    # Difference Transformation\n",
    "    diff_res = difference(result, 4)\n",
    "    \n",
    "    # StandardScaler \n",
    "    diff_res = array(diff_res).reshape(len(diff_res), 1)\n",
    "    standard_res = StandardScaler(with_mean = mean_, \n",
    "                                 with_std = std_ ).fit_transform(diff_res)\n",
    "    \n",
    "    # Normalization\n",
    "    norm_res = MinMaxScaler(feature_range=(1,2)).fit_transform(standard_res)\n",
    "    norm_res = [ s[0] for s in norm_res]\n",
    "    \n",
    "    df = pd.DataFrame(dict({col: norm_res}), index=s.index[4:])\n",
    "    X_test_new_list.append(df)\n",
    "    \n",
    "#     X_test_new.plot(title=col)\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_Test = pd.concat(X_test_new_list, axis=1)\n",
    "new_X_Test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a visual illustration of what happens when we transform our data using brown_transform(). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='before_and_after_transformation.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pipe&Hyper'></a>\n",
    "### Pipeline and Hyperparameters\n",
    "<a href='#top'>Top of Page</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Expt 2.2 - Train Model](#expt2.2train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline dictionary Classifiers\n",
    "pipelines = {\n",
    "    'l1' : make_pipeline(LogisticRegression(penalty='l1', random_state=123)),\n",
    "    'l2' : make_pipeline(LogisticRegression(penalty='l2', random_state=123)),\n",
    "    'rf' : make_pipeline(RandomForestClassifier(random_state=123)),\n",
    "    'gb' : make_pipeline(GradientBoostingClassifier(random_state=123))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression hyperparameters\n",
    "l1_hyperparameters = {\n",
    "    'logisticregression__C' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000],\n",
    "}\n",
    "\n",
    "l2_hyperparameters = {\n",
    "    'logisticregression__C' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000],\n",
    "}\n",
    "\n",
    "# Random Forest hyperparameters\n",
    "rf_hyperparameters = {\n",
    "    'randomforestclassifier__n_estimators': [100, 200],\n",
    "    'randomforestclassifier__max_features': ['auto', 'sqrt', 0.33],\n",
    "    'randomforestclassifier__min_samples_leaf': [1, 3, 5, 10]\n",
    "}\n",
    "\n",
    "# Boosted Tree hyperparameters\n",
    "gb_hyperparameters = {\n",
    "    'gradientboostingclassifier__n_estimators': [100, 200],\n",
    "    'gradientboostingclassifier__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'gradientboostingclassifier__max_depth': [1, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameters dictionary\n",
    "hyperparameters = {\n",
    "    'l1' : l1_hyperparameters,\n",
    "    'l2' : l2_hyperparameters,\n",
    "    'rf' : rf_hyperparameters,\n",
    "    'gb' : gb_hyperparameters\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Tune Model with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create empty dictionary called fitted_models\n",
    "fitted_models = {}\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    # Create cross-validation object from pipeline and hyperparameters\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(new_X_train, y_train[4:])\n",
    "    \n",
    "    # Store model in fitted_models[name] \n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    pred = model.predict_proba(new_X_Test)\n",
    "    pred = [p[1] for p in pred]\n",
    "    \n",
    "    print( name, roc_auc_score(y_test[4:], pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the highest AUROC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict PROBABILITIES using L1-regularized logistic regression\n",
    "pred = fitted_models['l2'].predict_proba(new_X_Test)\n",
    "\n",
    "# Get just the prediction for the positive class (1)\n",
    "pred = [p[1] for p in pred]\n",
    "\n",
    "# Display first 10 predictions\n",
    "print( np.round(pred[:10], 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve from y_test and pred\n",
    "fpr, tpr, thresholds = roc_curve(y_test[4:], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, label='l1')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Diagonal 45 degree line\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "\n",
    "# Axes limits and labels\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the classification where tech is the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now reversing the positive class from the Tech industry to Automobile. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swapping_targets(y):\n",
    "    swapped_y_list = []\n",
    "\n",
    "    for value in y.values:\n",
    "\n",
    "        if value == 1:\n",
    "            swapped_y_list.append(0)\n",
    "\n",
    "        if value == 0:\n",
    "            swapped_y_list.append(1)\n",
    "            \n",
    "    swapped_y = pd.Series(swapped_y_list, index=y.index)\n",
    "    \n",
    "    return swapped_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_train = swapping_targets(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_test = swapping_targets(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create empty dictionary called fitted_models\n",
    "fitted_models_2 = {}\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    # Create cross-validation object from pipeline and hyperparameters\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(new_X_train, new_y_train[4:])\n",
    "    \n",
    "    # Store model in fitted_models[name] \n",
    "    fitted_models_2[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for name, model in fitted_models_2.items():\n",
    "    pred = model.predict_proba(new_X_Test)\n",
    "    pred = [p[1] for p in pred]\n",
    "    \n",
    "    print( name, roc_auc_score(new_y_test[4:], pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swapping 0 and 1 produces the same results except for l1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict PROBABILITIES using L1-regularized logistic regression\n",
    "pred = fitted_models_2['l2'].predict_proba(new_X_Test)\n",
    "\n",
    "# Get just the prediction for the positive class (1)\n",
    "pred = [p[1] for p in pred]\n",
    "\n",
    "# Display first 10 predictions\n",
    "print( np.round(pred[:10], 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve from y_test and pred\n",
    "fpr, tpr, thresholds = roc_curve(new_y_test[4:], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, label='l1')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Diagonal 45 degree line\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "\n",
    "# Axes limits and labels\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://stackoverflow.com/questions/52373318/how-to-compare-roc-auc-scores-of-different-binary-classifiers-and-assess-statist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expt 1.1 Conclusion\n",
    "We will not try classifying Tesla into the models under these preprocessing conditions, because the predictability of the model is as good as chance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='expt1.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1.2 - individually transforming within companies across the same time-frame\n",
    "<a href='#top'>Top of Page</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df_1_2 = main_df_1_2[main_df_1_2['industry'].isna()]\n",
    "Train_df_1_2 = main_df_1_2[main_df_1_2['industry'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate object for target variable\n",
    "y = Train_df_1_2.industry\n",
    "\n",
    "# Create separate object for input features\n",
    "X = Train_df_1_2.drop('industry', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 54 216 54\n"
     ]
    }
   ],
   "source": [
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=1234,\n",
    "                                                    stratify=Train_df_1_2.industry)\n",
    "\n",
    "# Print number of observations in X_train, X_test, y_train, and y_test\n",
    "print( len(X_train), len(X_test), len(y_train), len(y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Matthew\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_test.sort_index(ascending=True, sort_remaining= True, inplace=True)\n",
    "X_train.sort_index(ascending=True, sort_remaining= True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = [name for name in X_train.company_name.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst = []\n",
    "for name in company_list:\n",
    "    company_df = X_train[X_train['company_name']==name]\n",
    "    df_lst.append(company_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_dfs = dict(zip(company_list, df_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon\n",
      "(39, 27)\n",
      "Netflix\n",
      "(39, 27)\n",
      "GM\n",
      "(35, 27)\n",
      "Microsoft\n",
      "(28, 27)\n",
      "Ford\n",
      "(23, 27)\n",
      "Apple\n",
      "(20, 27)\n",
      "Facebook\n",
      "(16, 27)\n",
      "Google\n",
      "(16, 27)\n"
     ]
    }
   ],
   "source": [
    "for name, df in company_dfs.items():\n",
    "    print(name)\n",
    "    partial_df = df.head(2)\n",
    "    print(df.shape)\n",
    "#     ICD.display(partial_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_brown_transform without difference transformation because too little data, seperating into company_df's drastically scarificed more data, expecially in X_test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_brown_transform(col_name, s):\n",
    "    # Create a list to hold parameter information before transformation.\n",
    "    para_list = []\n",
    "    \n",
    "    # Each Series -> variable s\n",
    "    s = df[col_name]\n",
    "\n",
    "    # Power Transform\n",
    "    try:\n",
    "        result, lmbda = boxcox(s)\n",
    "#         print('box_cox')\n",
    "#         print(lmbda)\n",
    "        para_list.append(['B-C', lmbda])\n",
    "        \n",
    "    except ValueError:\n",
    "        result, lmbda = yeojohnson(s.values.reshape(-1,1))\n",
    "#         print('Yeo-Johnson')\n",
    "        \n",
    "        if type(lmbda) == np.float64:\n",
    "            para_list.append(['Y-J', lmbda])\n",
    "            \n",
    "        else:\n",
    "    #         print(f'lambda {lmbda} {type(lmbda)}')\n",
    "            lmbda = lmbda[0]\n",
    "            para_list.append(['Y-J', lmbda])\n",
    "        \n",
    "#     # Difference Transform\n",
    "#     diff_res = difference(result, window)\n",
    "\n",
    "    # StandardScaler\n",
    "    # Turn 1-D array of lists into a 2-D array \n",
    "    #diff_res = array(diff_res).reshape(len(diff_res), 1)\n",
    "    \n",
    "    para_list.append(np.mean(result))\n",
    "    para_list.append(np.std(result))\n",
    "    \n",
    "    result = np.array(result).reshape(len(result), 1)\n",
    "    standard_res = StandardScaler().fit_transform(result)\n",
    "\n",
    "    # Normalization\n",
    "#     para_list.append(min(standard_res)[0])\n",
    "#     para_list.append(max(standard_res)[0])\n",
    "    \n",
    "    norm_res = MinMaxScaler(feature_range=(1,2)).fit_transform(standard_res)\n",
    "    norm_res = [ s[0] for s in norm_res]\n",
    "    trans_para_.update({ col_name : para_list} )\n",
    "    \n",
    "    return norm_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Perform columnar transformation on each company-dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon\n",
      "Netflix\n",
      "GM\n",
      "Microsoft\n",
      "Ford\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1960: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp2 = (x - v) * (fx - fw)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:122: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:1465: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(trans.var(axis=0))\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1959: RuntimeWarning: invalid value encountered in subtract\n",
      "  tmp1 = (x - w) * (fx - fv)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1960: RuntimeWarning: invalid value encountered in subtract\n",
      "  tmp2 = (x - v) * (fx - fw)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1963: RuntimeWarning: invalid value encountered in greater\n",
      "  if (tmp2 > 0.0):\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1969: RuntimeWarning: invalid value encountered in greater\n",
      "  if ((p > tmp2 * (a - x)) and (p < tmp2 * (b - x)) and\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:910: RuntimeWarning: divide by zero encountered in log\n",
      "  return (lmb - 1) * np.sum(logdata, axis=0) - N/2 * np.log(variance)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:2341: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  w = xb - ((xb - xc) * tmp2 - (xb - xa) * tmp1) / denom\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1959: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp1 = (x - w) * (fx - fv)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1960: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tmp2 = (x - v) * (fx - fw)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "Facebook\n",
      "Google\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:122: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:1465: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(trans.var(axis=0))\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1959: RuntimeWarning: invalid value encountered in subtract\n",
      "  tmp1 = (x - w) * (fx - fv)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1960: RuntimeWarning: invalid value encountered in subtract\n",
      "  tmp2 = (x - v) * (fx - fw)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1963: RuntimeWarning: invalid value encountered in greater\n",
      "  if (tmp2 > 0.0):\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1969: RuntimeWarning: invalid value encountered in greater\n",
      "  if ((p > tmp2 * (a - x)) and (p < tmp2 * (b - x)) and\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:1465: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(trans.var(axis=0))\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1959: RuntimeWarning: invalid value encountered in subtract\n",
      "  tmp1 = (x - w) * (fx - fv)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1960: RuntimeWarning: invalid value encountered in subtract\n",
      "  tmp2 = (x - v) * (fx - fw)\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1963: RuntimeWarning: invalid value encountered in greater\n",
      "  if (tmp2 > 0.0):\n",
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1969: RuntimeWarning: invalid value encountered in greater\n",
      "  if ((p > tmp2 * (a - x)) and (p < tmp2 * (b - x)) and\n"
     ]
    }
   ],
   "source": [
    "# { Company Name : {feat_name : [parameters]} }\n",
    "company_trans_para = {}\n",
    "\n",
    "trfm_com_df_lst = []\n",
    "\n",
    "# For each company\n",
    "for name, df in company_dfs.items():\n",
    "    print(name)\n",
    "    # Create dictionary to save the transformation parameters.\n",
    "    trans_para_ = {}\n",
    "\n",
    "    transformed_df_list = []\n",
    "\n",
    "    # Apply to all training columns within that company.\n",
    "    for col_name in df.columns:\n",
    "\n",
    "        # Apply only to numeric columns. \n",
    "        if df[col_name].dtypes == 'float64':\n",
    "\n",
    "            s = df[col_name]\n",
    "\n",
    "            # Brown's Transformation Suggestions\n",
    "            result = new_brown_transform(col_name, s)\n",
    "            \n",
    "            # Transformed Series \n",
    "            transformed_df = pd.DataFrame({col_name:result}, index=df.index )\n",
    "            transformed_df_list.append(transformed_df)\n",
    "#             transformed_df.plot(kind='line')\n",
    "#             print(col_name)\n",
    "#             plt.show()\n",
    "            \n",
    "    # Transformed Dataframe, gluing series tgt\n",
    "    trans_df = pd.concat(transformed_df_list, axis=1)\n",
    "    \n",
    "    # Append transformed df to df_list\n",
    "    trfm_com_df_lst.append(trans_df)\n",
    "    \n",
    "    # Saving transformation parameters. \n",
    "    company_trans_para[name] = trans_para_\n",
    "    \n",
    "#     if name == 'GM':\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### new_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accounts Receivable</th>\n",
       "      <th>Inventory</th>\n",
       "      <th>Total current assets</th>\n",
       "      <th>Total current liabilities</th>\n",
       "      <th>Total liabilities</th>\n",
       "      <th>Common Stock</th>\n",
       "      <th>New Deferred Revenue</th>\n",
       "      <th>New Property and Equipment</th>\n",
       "      <th>Total Non-Current Assets</th>\n",
       "      <th>Total_Assets</th>\n",
       "      <th>Non-Current Liabilities</th>\n",
       "      <th>Total Shareholder's Equity</th>\n",
       "      <th>Accounts Payables</th>\n",
       "      <th>Retained Earning</th>\n",
       "      <th>OCI</th>\n",
       "      <th>Short_term_investments</th>\n",
       "      <th>current_ratio</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>debt_to_equity_ratio</th>\n",
       "      <th>equity_multiplier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">2008</td>\n",
       "      <td>Q2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.001848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.199735</td>\n",
       "      <td>1.025731</td>\n",
       "      <td>1.272701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.060080</td>\n",
       "      <td>1.156798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.388793</td>\n",
       "      <td>1.009421</td>\n",
       "      <td>1.094787</td>\n",
       "      <td>1.826232</td>\n",
       "      <td>1.771855</td>\n",
       "      <td>1.258568</td>\n",
       "      <td>1.251105</td>\n",
       "      <td>1.243641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Q4</td>\n",
       "      <td>1.046352</td>\n",
       "      <td>1.018178</td>\n",
       "      <td>1.059731</td>\n",
       "      <td>1.036248</td>\n",
       "      <td>1.066570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.173824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.007041</td>\n",
       "      <td>1.180042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.090823</td>\n",
       "      <td>1.437582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.892237</td>\n",
       "      <td>1.881477</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">2009</td>\n",
       "      <td>Q1</td>\n",
       "      <td>1.000425</td>\n",
       "      <td>1.030468</td>\n",
       "      <td>1.036059</td>\n",
       "      <td>1.014677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.098298</td>\n",
       "      <td>1.071467</td>\n",
       "      <td>1.277832</td>\n",
       "      <td>1.027393</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.224426</td>\n",
       "      <td>1.048964</td>\n",
       "      <td>1.253527</td>\n",
       "      <td>1.314248</td>\n",
       "      <td>1.149511</td>\n",
       "      <td>1.900273</td>\n",
       "      <td>1.838581</td>\n",
       "      <td>1.096685</td>\n",
       "      <td>1.100137</td>\n",
       "      <td>1.095950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Q3</td>\n",
       "      <td>1.033905</td>\n",
       "      <td>1.089016</td>\n",
       "      <td>1.123494</td>\n",
       "      <td>1.087624</td>\n",
       "      <td>1.071278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.075862</td>\n",
       "      <td>1.101904</td>\n",
       "      <td>1.308189</td>\n",
       "      <td>1.096932</td>\n",
       "      <td>1.053939</td>\n",
       "      <td>1.276143</td>\n",
       "      <td>1.139437</td>\n",
       "      <td>1.046902</td>\n",
       "      <td>1.138366</td>\n",
       "      <td>1.245560</td>\n",
       "      <td>1.903074</td>\n",
       "      <td>1.859403</td>\n",
       "      <td>1.136933</td>\n",
       "      <td>1.138868</td>\n",
       "      <td>1.133541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Q4</td>\n",
       "      <td>1.086813</td>\n",
       "      <td>1.053891</td>\n",
       "      <td>1.113165</td>\n",
       "      <td>1.099344</td>\n",
       "      <td>1.083033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.131224</td>\n",
       "      <td>1.065460</td>\n",
       "      <td>1.260952</td>\n",
       "      <td>1.075823</td>\n",
       "      <td>1.064682</td>\n",
       "      <td>1.202285</td>\n",
       "      <td>1.158185</td>\n",
       "      <td>1.310867</td>\n",
       "      <td>1.291136</td>\n",
       "      <td>1.131042</td>\n",
       "      <td>1.806162</td>\n",
       "      <td>1.807651</td>\n",
       "      <td>1.357605</td>\n",
       "      <td>1.340533</td>\n",
       "      <td>1.332355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Accounts Receivable  Inventory  Total current assets  \\\n",
       "Year Quarter                                                         \n",
       "2008 Q2                  1.000000   1.000000              1.000000   \n",
       "     Q4                  1.046352   1.018178              1.059731   \n",
       "2009 Q1                  1.000425   1.030468              1.036059   \n",
       "     Q3                  1.033905   1.089016              1.123494   \n",
       "     Q4                  1.086813   1.053891              1.113165   \n",
       "\n",
       "              Total current liabilities  Total liabilities  Common Stock  \\\n",
       "Year Quarter                                                               \n",
       "2008 Q2                        1.000000           1.001848           1.0   \n",
       "     Q4                        1.036248           1.066570           1.0   \n",
       "2009 Q1                        1.014677           1.000000           1.0   \n",
       "     Q3                        1.087624           1.071278           1.0   \n",
       "     Q4                        1.099344           1.083033           1.0   \n",
       "\n",
       "              New Deferred Revenue  New Property and Equipment  \\\n",
       "Year Quarter                                                     \n",
       "2008 Q2                   1.199735                    1.025731   \n",
       "     Q4                   1.173824                    1.000000   \n",
       "2009 Q1                   1.098298                    1.071467   \n",
       "     Q3                   1.075862                    1.101904   \n",
       "     Q4                   1.131224                    1.065460   \n",
       "\n",
       "              Total Non-Current Assets  Total_Assets  Non-Current Liabilities  \\\n",
       "Year Quarter                                                                    \n",
       "2008 Q2                       1.272701      1.000000                 1.060080   \n",
       "     Q4                       1.000000      1.007041                 1.180042   \n",
       "2009 Q1                       1.277832      1.027393                 1.000000   \n",
       "     Q3                       1.308189      1.096932                 1.053939   \n",
       "     Q4                       1.260952      1.075823                 1.064682   \n",
       "\n",
       "              Total Shareholder's Equity  Accounts Payables  Retained Earning  \\\n",
       "Year Quarter                                                                    \n",
       "2008 Q2                         1.156798           1.000000          1.388793   \n",
       "     Q4                         1.000000           1.090823          1.437582   \n",
       "2009 Q1                         1.224426           1.048964          1.253527   \n",
       "     Q3                         1.276143           1.139437          1.046902   \n",
       "     Q4                         1.202285           1.158185          1.310867   \n",
       "\n",
       "                   OCI  Short_term_investments  current_ratio  quick_ratio  \\\n",
       "Year Quarter                                                                 \n",
       "2008 Q2       1.009421                1.094787       1.826232     1.771855   \n",
       "     Q4       1.000000                1.000000       1.892237     1.881477   \n",
       "2009 Q1       1.314248                1.149511       1.900273     1.838581   \n",
       "     Q3       1.138366                1.245560       1.903074     1.859403   \n",
       "     Q4       1.291136                1.131042       1.806162     1.807651   \n",
       "\n",
       "              debt_ratio  debt_to_equity_ratio  equity_multiplier  \n",
       "Year Quarter                                                       \n",
       "2008 Q2         1.258568              1.251105           1.243641  \n",
       "     Q4         2.000000              2.000000           2.000000  \n",
       "2009 Q1         1.096685              1.100137           1.095950  \n",
       "     Q3         1.136933              1.138868           1.133541  \n",
       "     Q4         1.357605              1.340533           1.332355  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_train = pd.concat(trfm_com_df_lst, axis=0)\n",
    "print(new_X_train.shape)\n",
    "new_X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the training transformations onto X_test with trans_para_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_lst = []\n",
    "for name in company_list:\n",
    "    company_df = X_test[X_test['company_name']==name]\n",
    "    test_df_lst.append(company_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_company_dfs = dict(zip(company_list, test_df_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year  Quarter\n",
       "2014  Q1         1.349700e+10\n",
       "2015  Q3         1.144400e+10\n",
       "2017  Q1         1.288200e+10\n",
       "2018  Q1         1.720800e+10\n",
       "Name: Accounts Receivable, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Too little data!!!! \n",
    "test_company_dfs['Microsoft']['Accounts Receivable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon is transformed and added.\n",
      "Netflix is transformed and added.\n",
      "GM is transformed and added.\n",
      "Microsoft is transformed and added.\n",
      "Ford is transformed and added.\n",
      "Apple is transformed and added.\n",
      "Facebook is transformed and added.\n",
      "Google is transformed and added.\n"
     ]
    }
   ],
   "source": [
    "# X_test_new = scaler.transform(X_test)\n",
    "X_test_new_list = []\n",
    "\n",
    "for company, trans_para_ in company_trans_para.items():\n",
    "    \n",
    "    transformed_df_list = []\n",
    "    \n",
    "    for col, parameters in trans_para_.items():\n",
    "\n",
    "        power_T = parameters[0][0]\n",
    "\n",
    "        lmbda = parameters[0][1]\n",
    "\n",
    "        mean_ = parameters[1]\n",
    "\n",
    "        std_ = parameters[2]\n",
    "\n",
    "        s = test_company_dfs[company][col]\n",
    "\n",
    "        # Power Transformation\n",
    "        if power_T == 'B-C':\n",
    "            try:\n",
    "                result = boxcox(s, lmbda)\n",
    "                \n",
    "            except: \n",
    "#                 print('Original s \\n', s)\n",
    "                ss = s.copy()\n",
    "                ss = np.array([num+1 if num == 0 else num for num in s ])\n",
    "#                 print('New s \\n', s)\n",
    "                result = boxcox(ss, lmbda) \n",
    "                \n",
    "#                 print(company, 'has a negative value.')\n",
    "#                 s.plot(title=col)\n",
    "#                 print(s)\n",
    "#                 result = boxcox(abs(s), lmbda)\n",
    "                \n",
    "        elif power_T == 'Y-J':\n",
    "            result = yeojohnson(s, lmbda)\n",
    "           \n",
    "        # Difference Transformation\n",
    "#         diff_res = difference(result, 4)\n",
    "        \n",
    "        # StandardScaler \n",
    "#         diff_res = array(diff_res).reshape(len(diff_res), 1)\n",
    "        result = np.array(result).reshape(len(result), 1)\n",
    "    \n",
    "        try:\n",
    "            standard_res = StandardScaler(with_mean = mean_, \n",
    "                                     with_std = std_ ).fit_transform(result)\n",
    "        except:\n",
    "            print(company, col)\n",
    "            print('wrong?')\n",
    "            print(result)\n",
    "            print('after difference() and reshape', diff_res)\n",
    "        # Normalization\n",
    "        norm_res = MinMaxScaler(feature_range=(1,2)).fit_transform(standard_res)\n",
    "        norm_res = [ s[0] for s in norm_res]\n",
    "        \n",
    "        # Transformed Series\n",
    "        transformed_df = pd.DataFrame(dict({col: norm_res}), index=s.index)\n",
    "        transformed_df_list.append(transformed_df)\n",
    "        \n",
    "    # Transformed Dataframe, gluing series tgt, per company\n",
    "    trans_df = pd.concat(transformed_df_list, axis=1)\n",
    "    \n",
    "    # Append transformed df to df_list\n",
    "    X_test_new_list.append(trans_df)\n",
    "    \n",
    "    print(f'{company} is transformed and added.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accounts Receivable</th>\n",
       "      <th>Inventory</th>\n",
       "      <th>Total current assets</th>\n",
       "      <th>Total current liabilities</th>\n",
       "      <th>Total liabilities</th>\n",
       "      <th>Common Stock</th>\n",
       "      <th>New Deferred Revenue</th>\n",
       "      <th>New Property and Equipment</th>\n",
       "      <th>Total Non-Current Assets</th>\n",
       "      <th>Total_Assets</th>\n",
       "      <th>Non-Current Liabilities</th>\n",
       "      <th>Total Shareholder's Equity</th>\n",
       "      <th>Accounts Payables</th>\n",
       "      <th>Retained Earning</th>\n",
       "      <th>OCI</th>\n",
       "      <th>Short_term_investments</th>\n",
       "      <th>current_ratio</th>\n",
       "      <th>quick_ratio</th>\n",
       "      <th>debt_ratio</th>\n",
       "      <th>debt_to_equity_ratio</th>\n",
       "      <th>equity_multiplier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2007</td>\n",
       "      <td>Q4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.127505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.404015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.129524</td>\n",
       "      <td>1.832628</td>\n",
       "      <td>1.818130</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">2008</td>\n",
       "      <td>Q1</td>\n",
       "      <td>1.091351</td>\n",
       "      <td>1.046824</td>\n",
       "      <td>1.050432</td>\n",
       "      <td>1.088711</td>\n",
       "      <td>1.030803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.142676</td>\n",
       "      <td>1.038140</td>\n",
       "      <td>1.399274</td>\n",
       "      <td>1.079680</td>\n",
       "      <td>1.021019</td>\n",
       "      <td>1.261943</td>\n",
       "      <td>1.007451</td>\n",
       "      <td>1.300261</td>\n",
       "      <td>1.098131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.386436</td>\n",
       "      <td>1.468221</td>\n",
       "      <td>1.364138</td>\n",
       "      <td>1.257786</td>\n",
       "      <td>1.252524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Q3</td>\n",
       "      <td>1.098041</td>\n",
       "      <td>1.094951</td>\n",
       "      <td>1.085208</td>\n",
       "      <td>1.056393</td>\n",
       "      <td>1.007153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.167494</td>\n",
       "      <td>1.069325</td>\n",
       "      <td>1.423297</td>\n",
       "      <td>1.108999</td>\n",
       "      <td>1.029242</td>\n",
       "      <td>1.377144</td>\n",
       "      <td>1.060960</td>\n",
       "      <td>1.232611</td>\n",
       "      <td>1.346135</td>\n",
       "      <td>1.008739</td>\n",
       "      <td>1.940203</td>\n",
       "      <td>1.827057</td>\n",
       "      <td>1.056946</td>\n",
       "      <td>1.041453</td>\n",
       "      <td>1.039704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2009</td>\n",
       "      <td>Q2</td>\n",
       "      <td>1.092618</td>\n",
       "      <td>1.096830</td>\n",
       "      <td>1.142007</td>\n",
       "      <td>1.095042</td>\n",
       "      <td>1.031167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.026233</td>\n",
       "      <td>1.115091</td>\n",
       "      <td>1.453183</td>\n",
       "      <td>1.150694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.430942</td>\n",
       "      <td>1.094119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.312132</td>\n",
       "      <td>1.206737</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2011</td>\n",
       "      <td>Q3</td>\n",
       "      <td>1.331258</td>\n",
       "      <td>1.397845</td>\n",
       "      <td>1.402166</td>\n",
       "      <td>1.350001</td>\n",
       "      <td>1.286902</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.063691</td>\n",
       "      <td>1.361383</td>\n",
       "      <td>1.537167</td>\n",
       "      <td>1.394488</td>\n",
       "      <td>1.238229</td>\n",
       "      <td>1.614969</td>\n",
       "      <td>1.400039</td>\n",
       "      <td>1.395643</td>\n",
       "      <td>1.572810</td>\n",
       "      <td>1.531816</td>\n",
       "      <td>1.822973</td>\n",
       "      <td>1.667030</td>\n",
       "      <td>1.022608</td>\n",
       "      <td>1.016769</td>\n",
       "      <td>1.015999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Accounts Receivable  Inventory  Total current assets  \\\n",
       "Year Quarter                                                         \n",
       "2007 Q4                  1.000000   1.000000              1.000000   \n",
       "2008 Q1                  1.091351   1.046824              1.050432   \n",
       "     Q3                  1.098041   1.094951              1.085208   \n",
       "2009 Q2                  1.092618   1.096830              1.142007   \n",
       "2011 Q3                  1.331258   1.397845              1.402166   \n",
       "\n",
       "              Total current liabilities  Total liabilities  Common Stock  \\\n",
       "Year Quarter                                                               \n",
       "2007 Q4                        1.000000           1.000000           1.0   \n",
       "2008 Q1                        1.088711           1.030803           1.0   \n",
       "     Q3                        1.056393           1.007153           1.0   \n",
       "2009 Q2                        1.095042           1.031167           1.0   \n",
       "2011 Q3                        1.350001           1.286902           2.0   \n",
       "\n",
       "              New Deferred Revenue  New Property and Equipment  \\\n",
       "Year Quarter                                                     \n",
       "2007 Q4                   1.000000                    1.000000   \n",
       "2008 Q1                   1.142676                    1.038140   \n",
       "     Q3                   1.167494                    1.069325   \n",
       "2009 Q2                   1.026233                    1.115091   \n",
       "2011 Q3                   1.063691                    1.361383   \n",
       "\n",
       "              Total Non-Current Assets  Total_Assets  Non-Current Liabilities  \\\n",
       "Year Quarter                                                                    \n",
       "2007 Q4                       1.000000      1.000000                 1.127505   \n",
       "2008 Q1                       1.399274      1.079680                 1.021019   \n",
       "     Q3                       1.423297      1.108999                 1.029242   \n",
       "2009 Q2                       1.453183      1.150694                 1.000000   \n",
       "2011 Q3                       1.537167      1.394488                 1.238229   \n",
       "\n",
       "              Total Shareholder's Equity  Accounts Payables  Retained Earning  \\\n",
       "Year Quarter                                                                    \n",
       "2007 Q4                         1.000000           1.000000          1.404015   \n",
       "2008 Q1                         1.261943           1.007451          1.300261   \n",
       "     Q3                         1.377144           1.060960          1.232611   \n",
       "2009 Q2                         1.430942           1.094119          1.000000   \n",
       "2011 Q3                         1.614969           1.400039          1.395643   \n",
       "\n",
       "                   OCI  Short_term_investments  current_ratio  quick_ratio  \\\n",
       "Year Quarter                                                                 \n",
       "2007 Q4       1.000000                1.129524       1.832628     1.818130   \n",
       "2008 Q1       1.098131                1.000000       1.386436     1.468221   \n",
       "     Q3       1.346135                1.008739       1.940203     1.827057   \n",
       "2009 Q2       1.312132                1.206737       2.000000     2.000000   \n",
       "2011 Q3       1.572810                1.531816       1.822973     1.667030   \n",
       "\n",
       "              debt_ratio  debt_to_equity_ratio  equity_multiplier  \n",
       "Year Quarter                                                       \n",
       "2007 Q4         2.000000              2.000000           2.000000  \n",
       "2008 Q1         1.364138              1.257786           1.252524  \n",
       "     Q3         1.056946              1.041453           1.039704  \n",
       "2009 Q2         1.000000              1.000000           1.000000  \n",
       "2011 Q3         1.022608              1.016769           1.015999  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_Test = pd.concat(X_test_new_list, axis=0)\n",
    "print(new_X_Test.shape)\n",
    "new_X_Test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the same pipeline and hyperparameters as experiment 1.1. \n",
    "<a id='expt2.2train'></a>\n",
    "\n",
    "[Click](#pipe&Hyper)\n",
    "here to view again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Tune Model with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf has been fitted.\n",
      "gb has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create empty dictionary called fitted_models\n",
    "fitted_models = {}\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    # Create cross-validation object from pipeline and hyperparameters\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(new_X_train, y_train)\n",
    "    \n",
    "    # Store model in fitted_models[name] \n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 0.45299145299145305\n",
      "l2 0.5008547008547009\n",
      "rf 0.5487179487179488\n",
      "gb 0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    pred = model.predict_proba(new_X_Test)\n",
    "    pred = [p[1] for p in pred]\n",
    "    \n",
    "    print( name, roc_auc_score(y_test, pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expt 1.2 Conclusion\n",
    "Our best classifer did not perform better than chance. Whether we transform the features across multiple industies as a whole or transform within each company. \n",
    "However, unlike expt 1.1, expt 1.2 did not perform the difference transformation. This may introduce some confounding variables, but since we did not have enough data, it is a limitation of this study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2.1 - MANOVA F-test\n",
    "<a href='#top'>Top of Page</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.MANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='expt3.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3.1 - k-means clustering\n",
    "<a href='#top'>Top of Page</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='expt4.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4.1 - ML Time Series Analysis\n",
    "<a href='#top'>Top of Page</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationarity and detrending (ADF/KPSS)\n",
    "\n",
    "\n",
    "https://www.statsmodels.org/stable/examples/notebooks/generated/stationarity_detrending_adf_kpss.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='appendix'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "<a href='#top'>Top of Page</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing BoxCox and Y-J have unexpected results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inventory positive outcome for Y-J, Total current assets negative outcome for Y-J but positive outcome for Box-Cox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inventory = X_train.Inventory\n",
    "# print(Inventory)\n",
    "new_inventory, lmbda = yeojohnson(Inventory) \n",
    "pd.DataFrame(new_inventory).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newB_TCA = brown_transform('Total current assets', X_train['Total current assets'], 4)\n",
    "# pd.DataFrame(newB_TCA).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCA = X_train['Total current assets']\n",
    "TCA.plot()\n",
    "plt.show()\n",
    "# print(TCA.describe())\n",
    "# print(TCA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCA = X_train['Total current assets']\n",
    "# print(TCA)\n",
    "new_TCA, lmbda = yeojohnson(TCA) \n",
    "# print(lmbda)\n",
    "# pd.DataFrame(new_TCA).plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Brown's method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "s = tsla_df['Accounts Receivable']\n",
    "result, lmbda = boxcox(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(result).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference dataset\n",
    "def difference(data, interval):\n",
    "    return [data[i] - data[i - interval] for i in range(interval, len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_res = difference(result, 4)\n",
    "pd.Series(diff_res).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = difference(power_s, 4)\n",
    "sample = np.array(sample).reshape(-1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_norm = pd.DataFrame(StandardScaler().fit_transform(sample))\n",
    "sample_norm.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "diff_res = [x for x in diff_res]\n",
    "diff_res = array(diff_res).reshape(len(diff_res), 1)\n",
    "# print(pd.Series(diff_res[0]).plot())\n",
    "# plt.show()\n",
    "standard_res = StandardScaler().fit_transform(diff_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(standard_res).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "norm_res = MinMaxScaler().fit_transform(standard_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(norm_res).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scikit-Learn built-in preprocessing methods, does not yield proper results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power Transform\n",
    "from sklearn.preprocessing import power_transform\n",
    "\n",
    "# Difference Transform\n",
    "# Missing\n",
    "\n",
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalization\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(s.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 'Accounts Receivable' as an example, plot different transformations.\n",
    "s = tsla_df['Short_term_investments']\n",
    "\n",
    "power_s = power_transform(s.values.reshape(-1,1), \n",
    "                          method='box-cox', \n",
    "                          standardize=False)\n",
    "# print(power_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accounts Receivable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Original\n",
    "# Before Power Transformations\n",
    "print(pd.DataFrame(s).plot())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accounts Receivable\n",
    "# After Power Transformations - box-cox\n",
    "print(pd.DataFrame(power_s).plot())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Accounts Receivable\n",
    "# After Power Transformations - yeo-johnson\n",
    "print(pd.DataFrame(power_s).plot())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Short_term_investments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "# Before Power Transformations\n",
    "print(pd.DataFrame(s).plot())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short_term_investments\n",
    "# After Power Transformations - box-cox\n",
    " **ERROR - **\n",
    "ValueError: The Box-Cox transformation can only be applied to strictly positive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short_term_investments\n",
    "# After Power Transformations - yeo-johnson\n",
    "print(pd.DataFrame(power_s).plot())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_s = [num[0] for num in power_s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference Transform\n",
    "Same as Brown's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference dataset\n",
    "def difference(data, interval):\n",
    "    return [data[i] - data[i - interval] for i in range(interval, len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diff_s = difference(power_s, 4)\n",
    "pd.Series(diff_s).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_s = normalize(diff_s, norm='l1', axis=0)\n",
    "pd.DataFrame(norm_s).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_s = [[num] for num in diff_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_s = StandardScaler().fit_transform(diff_s)\n",
    "pd.DataFrame(standard_s).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of final products between scikit-learn and Brown's process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_s == norm_res\n",
    "print(type(norm_s), type(norm_res))\n",
    "norm_s_df = pd.DataFrame( norm_s)\n",
    "norm_res_df = pd.DataFrame( norm_res)\n",
    "norm_s_df.plot()\n",
    "norm_res_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#top'>Top of Page</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
